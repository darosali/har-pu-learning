{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab80afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pu_loss import PULoss, PULossWrapped, PURankingLoss\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0b0b1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f75525",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\"data\", \"UCI HAR Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8efa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = os.path.join(DATA_DIR, \"features.txt\")\n",
    "features = pd.read_csv(features_path, sep='\\s+', header=None, names=['index', 'feature_name'])['feature_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b82e512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"train\", \"X_train.txt\"),\n",
    "    sep='\\s+',\n",
    "    header=None,\n",
    ")\n",
    "X_test = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"test\", \"X_test.txt\"),\n",
    "    sep='\\s+',\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "y_train = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"train\", \"y_train.txt\"),\n",
    "    header=None\n",
    ")[0]\n",
    "y_test = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"test\", \"y_test.txt\"),\n",
    "    header=None\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6b88c6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>320</th>\n",
       "      <th>321</th>\n",
       "      <th>322</th>\n",
       "      <th>323</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "      <th>346</th>\n",
       "      <th>347</th>\n",
       "      <th>348</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "      <th>463</th>\n",
       "      <th>464</th>\n",
       "      <th>465</th>\n",
       "      <th>466</th>\n",
       "      <th>467</th>\n",
       "      <th>468</th>\n",
       "      <th>469</th>\n",
       "      <th>470</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "      <th>484</th>\n",
       "      <th>485</th>\n",
       "      <th>486</th>\n",
       "      <th>487</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "      <th>513</th>\n",
       "      <th>514</th>\n",
       "      <th>515</th>\n",
       "      <th>516</th>\n",
       "      <th>517</th>\n",
       "      <th>518</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "      <th>529</th>\n",
       "      <th>530</th>\n",
       "      <th>531</th>\n",
       "      <th>532</th>\n",
       "      <th>533</th>\n",
       "      <th>534</th>\n",
       "      <th>535</th>\n",
       "      <th>536</th>\n",
       "      <th>537</th>\n",
       "      <th>538</th>\n",
       "      <th>539</th>\n",
       "      <th>540</th>\n",
       "      <th>541</th>\n",
       "      <th>542</th>\n",
       "      <th>543</th>\n",
       "      <th>544</th>\n",
       "      <th>545</th>\n",
       "      <th>546</th>\n",
       "      <th>547</th>\n",
       "      <th>548</th>\n",
       "      <th>549</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>-0.567378</td>\n",
       "      <td>-0.744413</td>\n",
       "      <td>0.852947</td>\n",
       "      <td>0.685845</td>\n",
       "      <td>0.814263</td>\n",
       "      <td>-0.965523</td>\n",
       "      <td>-0.999945</td>\n",
       "      <td>-0.999863</td>\n",
       "      <td>-0.994612</td>\n",
       "      <td>-0.994231</td>\n",
       "      <td>-0.987614</td>\n",
       "      <td>-0.943220</td>\n",
       "      <td>-0.407747</td>\n",
       "      <td>-0.679338</td>\n",
       "      <td>-0.602122</td>\n",
       "      <td>0.929294</td>\n",
       "      <td>-0.853011</td>\n",
       "      <td>0.359910</td>\n",
       "      <td>-0.058526</td>\n",
       "      <td>0.256892</td>\n",
       "      <td>-0.224848</td>\n",
       "      <td>0.264106</td>\n",
       "      <td>-0.095246</td>\n",
       "      <td>0.278851</td>\n",
       "      <td>-0.465085</td>\n",
       "      <td>0.491936</td>\n",
       "      <td>-0.190884</td>\n",
       "      <td>0.376314</td>\n",
       "      <td>0.435129</td>\n",
       "      <td>0.660790</td>\n",
       "      <td>0.963396</td>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.985250</td>\n",
       "      <td>-0.981708</td>\n",
       "      <td>-0.877625</td>\n",
       "      <td>-0.985001</td>\n",
       "      <td>-0.984416</td>\n",
       "      <td>-0.894677</td>\n",
       "      <td>0.892055</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>0.977436</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>0.899469</td>\n",
       "      <td>-0.970905</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.984325</td>\n",
       "      <td>-0.988849</td>\n",
       "      <td>-0.917743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.113806</td>\n",
       "      <td>-0.590425</td>\n",
       "      <td>0.591146</td>\n",
       "      <td>-0.591773</td>\n",
       "      <td>0.592469</td>\n",
       "      <td>-0.745449</td>\n",
       "      <td>0.720862</td>\n",
       "      <td>-0.712372</td>\n",
       "      <td>0.711300</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>0.995675</td>\n",
       "      <td>-0.995668</td>\n",
       "      <td>0.991653</td>\n",
       "      <td>0.570222</td>\n",
       "      <td>0.439027</td>\n",
       "      <td>0.986913</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>-0.993519</td>\n",
       "      <td>-0.988360</td>\n",
       "      <td>-0.993575</td>\n",
       "      <td>-0.994488</td>\n",
       "      <td>-0.986207</td>\n",
       "      <td>-0.992818</td>\n",
       "      <td>-0.985180</td>\n",
       "      <td>-0.991994</td>\n",
       "      <td>-0.993119</td>\n",
       "      <td>0.989835</td>\n",
       "      <td>0.991957</td>\n",
       "      <td>0.990519</td>\n",
       "      <td>-0.993522</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.999820</td>\n",
       "      <td>-0.999878</td>\n",
       "      <td>-0.994364</td>\n",
       "      <td>-0.986025</td>\n",
       "      <td>-0.989234</td>\n",
       "      <td>-0.819949</td>\n",
       "      <td>-0.793046</td>\n",
       "      <td>-0.888853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.220747</td>\n",
       "      <td>0.636831</td>\n",
       "      <td>0.387644</td>\n",
       "      <td>0.241401</td>\n",
       "      <td>-0.052253</td>\n",
       "      <td>0.264177</td>\n",
       "      <td>0.373439</td>\n",
       "      <td>0.341778</td>\n",
       "      <td>-0.569791</td>\n",
       "      <td>0.265399</td>\n",
       "      <td>-0.477875</td>\n",
       "      <td>-0.385300</td>\n",
       "      <td>0.033644</td>\n",
       "      <td>-0.126511</td>\n",
       "      <td>-0.006101</td>\n",
       "      <td>-0.031365</td>\n",
       "      <td>0.107725</td>\n",
       "      <td>-0.985310</td>\n",
       "      <td>-0.976623</td>\n",
       "      <td>-0.992205</td>\n",
       "      <td>-0.984586</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>-0.992362</td>\n",
       "      <td>-0.867044</td>\n",
       "      <td>-0.933786</td>\n",
       "      <td>-0.747566</td>\n",
       "      <td>0.847308</td>\n",
       "      <td>0.914895</td>\n",
       "      <td>0.830841</td>\n",
       "      <td>-0.967184</td>\n",
       "      <td>-0.999578</td>\n",
       "      <td>-0.999354</td>\n",
       "      <td>-0.999763</td>\n",
       "      <td>-0.983438</td>\n",
       "      <td>-0.978614</td>\n",
       "      <td>-0.992966</td>\n",
       "      <td>0.082632</td>\n",
       "      <td>0.202268</td>\n",
       "      <td>-0.168757</td>\n",
       "      <td>0.096323</td>\n",
       "      <td>-0.274985</td>\n",
       "      <td>0.498644</td>\n",
       "      <td>-0.220317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.972971</td>\n",
       "      <td>0.316655</td>\n",
       "      <td>0.375726</td>\n",
       "      <td>0.723399</td>\n",
       "      <td>-0.771112</td>\n",
       "      <td>0.690213</td>\n",
       "      <td>-0.331831</td>\n",
       "      <td>0.709584</td>\n",
       "      <td>0.134873</td>\n",
       "      <td>0.301099</td>\n",
       "      <td>-0.099167</td>\n",
       "      <td>-0.055517</td>\n",
       "      <td>-0.061986</td>\n",
       "      <td>-0.992111</td>\n",
       "      <td>-0.992519</td>\n",
       "      <td>-0.992055</td>\n",
       "      <td>-0.992165</td>\n",
       "      <td>-0.994942</td>\n",
       "      <td>-0.992619</td>\n",
       "      <td>-0.990156</td>\n",
       "      <td>-0.986743</td>\n",
       "      <td>-0.992042</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>0.989352</td>\n",
       "      <td>-0.994453</td>\n",
       "      <td>-0.999938</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.999923</td>\n",
       "      <td>-0.992300</td>\n",
       "      <td>-0.996939</td>\n",
       "      <td>-0.992243</td>\n",
       "      <td>-0.589851</td>\n",
       "      <td>-0.688459</td>\n",
       "      <td>-0.572107</td>\n",
       "      <td>0.292376</td>\n",
       "      <td>-0.361998</td>\n",
       "      <td>0.405543</td>\n",
       "      <td>-0.039007</td>\n",
       "      <td>0.989284</td>\n",
       "      <td>-0.414560</td>\n",
       "      <td>0.391603</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>0.927270</td>\n",
       "      <td>-0.572370</td>\n",
       "      <td>0.691619</td>\n",
       "      <td>0.468290</td>\n",
       "      <td>-0.131077</td>\n",
       "      <td>-0.087160</td>\n",
       "      <td>0.336247</td>\n",
       "      <td>-0.959434</td>\n",
       "      <td>-0.950551</td>\n",
       "      <td>-0.957993</td>\n",
       "      <td>-0.946305</td>\n",
       "      <td>-0.992556</td>\n",
       "      <td>-0.959434</td>\n",
       "      <td>-0.998493</td>\n",
       "      <td>-0.957637</td>\n",
       "      <td>-0.232582</td>\n",
       "      <td>-0.173179</td>\n",
       "      <td>-0.022897</td>\n",
       "      <td>0.094832</td>\n",
       "      <td>0.191817</td>\n",
       "      <td>-0.959434</td>\n",
       "      <td>-0.950551</td>\n",
       "      <td>-0.957993</td>\n",
       "      <td>-0.946305</td>\n",
       "      <td>-0.992556</td>\n",
       "      <td>-0.959434</td>\n",
       "      <td>-0.998493</td>\n",
       "      <td>-0.957637</td>\n",
       "      <td>-0.232582</td>\n",
       "      <td>-0.173179</td>\n",
       "      <td>-0.022897</td>\n",
       "      <td>0.094832</td>\n",
       "      <td>0.191817</td>\n",
       "      <td>-0.993306</td>\n",
       "      <td>-0.994336</td>\n",
       "      <td>-0.994500</td>\n",
       "      <td>-0.992784</td>\n",
       "      <td>-0.991208</td>\n",
       "      <td>-0.993306</td>\n",
       "      <td>-0.999892</td>\n",
       "      <td>-0.992934</td>\n",
       "      <td>-0.863415</td>\n",
       "      <td>0.283085</td>\n",
       "      <td>-0.237309</td>\n",
       "      <td>-0.105432</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.968959</td>\n",
       "      <td>-0.964335</td>\n",
       "      <td>-0.957245</td>\n",
       "      <td>-0.975060</td>\n",
       "      <td>-0.991554</td>\n",
       "      <td>-0.968959</td>\n",
       "      <td>-0.999286</td>\n",
       "      <td>-0.949766</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>0.572511</td>\n",
       "      <td>-0.738602</td>\n",
       "      <td>0.212578</td>\n",
       "      <td>0.433405</td>\n",
       "      <td>-0.994248</td>\n",
       "      <td>-0.991368</td>\n",
       "      <td>-0.993143</td>\n",
       "      <td>-0.988936</td>\n",
       "      <td>-0.993486</td>\n",
       "      <td>-0.994248</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.994547</td>\n",
       "      <td>-0.619768</td>\n",
       "      <td>0.292840</td>\n",
       "      <td>-0.176889</td>\n",
       "      <td>-0.145779</td>\n",
       "      <td>-0.124072</td>\n",
       "      <td>-0.994783</td>\n",
       "      <td>-0.982984</td>\n",
       "      <td>-0.939269</td>\n",
       "      <td>-0.995422</td>\n",
       "      <td>-0.983133</td>\n",
       "      <td>-0.906165</td>\n",
       "      <td>-0.996889</td>\n",
       "      <td>-0.984519</td>\n",
       "      <td>-0.932082</td>\n",
       "      <td>-0.993756</td>\n",
       "      <td>-0.983163</td>\n",
       "      <td>-0.885054</td>\n",
       "      <td>-0.993962</td>\n",
       "      <td>-0.993446</td>\n",
       "      <td>-0.923428</td>\n",
       "      <td>-0.974733</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999689</td>\n",
       "      <td>-0.994891</td>\n",
       "      <td>-0.995926</td>\n",
       "      <td>-0.989709</td>\n",
       "      <td>-0.987991</td>\n",
       "      <td>-0.946357</td>\n",
       "      <td>-0.904748</td>\n",
       "      <td>-0.591302</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.252483</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>-0.052050</td>\n",
       "      <td>0.142051</td>\n",
       "      <td>-0.150682</td>\n",
       "      <td>-0.220547</td>\n",
       "      <td>-0.558739</td>\n",
       "      <td>0.246769</td>\n",
       "      <td>-0.007416</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999987</td>\n",
       "      <td>-0.999979</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.999932</td>\n",
       "      <td>-0.999725</td>\n",
       "      <td>-0.999670</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999870</td>\n",
       "      <td>-0.999776</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.999919</td>\n",
       "      <td>-0.999657</td>\n",
       "      <td>-0.999860</td>\n",
       "      <td>-0.999867</td>\n",
       "      <td>-0.999863</td>\n",
       "      <td>-0.999738</td>\n",
       "      <td>-0.999732</td>\n",
       "      <td>-0.999493</td>\n",
       "      <td>-0.999814</td>\n",
       "      <td>-0.999682</td>\n",
       "      <td>-0.999839</td>\n",
       "      <td>-0.999738</td>\n",
       "      <td>-0.999612</td>\n",
       "      <td>-0.999687</td>\n",
       "      <td>-0.999839</td>\n",
       "      <td>-0.993592</td>\n",
       "      <td>-0.999476</td>\n",
       "      <td>-0.999662</td>\n",
       "      <td>-0.999642</td>\n",
       "      <td>-0.999293</td>\n",
       "      <td>-0.997892</td>\n",
       "      <td>-0.995932</td>\n",
       "      <td>-0.995146</td>\n",
       "      <td>-0.994740</td>\n",
       "      <td>-0.999688</td>\n",
       "      <td>-0.998925</td>\n",
       "      <td>-0.995671</td>\n",
       "      <td>-0.994877</td>\n",
       "      <td>-0.999454</td>\n",
       "      <td>-0.992332</td>\n",
       "      <td>-0.987170</td>\n",
       "      <td>-0.989696</td>\n",
       "      <td>-0.995821</td>\n",
       "      <td>-0.990936</td>\n",
       "      <td>-0.997052</td>\n",
       "      <td>-0.993805</td>\n",
       "      <td>-0.990519</td>\n",
       "      <td>-0.996993</td>\n",
       "      <td>-0.996737</td>\n",
       "      <td>-0.991975</td>\n",
       "      <td>-0.993242</td>\n",
       "      <td>-0.998349</td>\n",
       "      <td>-0.991108</td>\n",
       "      <td>-0.959885</td>\n",
       "      <td>-0.990515</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.999820</td>\n",
       "      <td>-0.999884</td>\n",
       "      <td>-0.993026</td>\n",
       "      <td>-0.991373</td>\n",
       "      <td>-0.996240</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.870385</td>\n",
       "      <td>0.210697</td>\n",
       "      <td>0.263708</td>\n",
       "      <td>-0.703686</td>\n",
       "      <td>-0.903743</td>\n",
       "      <td>-0.582574</td>\n",
       "      <td>-0.936310</td>\n",
       "      <td>-0.507345</td>\n",
       "      <td>-0.805536</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999980</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999955</td>\n",
       "      <td>-0.999919</td>\n",
       "      <td>-0.999640</td>\n",
       "      <td>-0.999483</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.999811</td>\n",
       "      <td>-0.999485</td>\n",
       "      <td>-0.999981</td>\n",
       "      <td>-0.999852</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.999900</td>\n",
       "      <td>-0.999824</td>\n",
       "      <td>-0.999860</td>\n",
       "      <td>-0.999728</td>\n",
       "      <td>-0.999729</td>\n",
       "      <td>-0.999567</td>\n",
       "      <td>-0.999765</td>\n",
       "      <td>-0.999900</td>\n",
       "      <td>-0.999815</td>\n",
       "      <td>-0.999710</td>\n",
       "      <td>-0.999596</td>\n",
       "      <td>-0.999852</td>\n",
       "      <td>-0.999822</td>\n",
       "      <td>-0.999400</td>\n",
       "      <td>-0.999766</td>\n",
       "      <td>-0.999958</td>\n",
       "      <td>-0.999950</td>\n",
       "      <td>-0.999838</td>\n",
       "      <td>-0.999814</td>\n",
       "      <td>-0.998781</td>\n",
       "      <td>-0.998578</td>\n",
       "      <td>-0.999620</td>\n",
       "      <td>-0.999984</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>-0.998681</td>\n",
       "      <td>-0.999844</td>\n",
       "      <td>-0.999928</td>\n",
       "      <td>-0.986574</td>\n",
       "      <td>-0.981762</td>\n",
       "      <td>-0.989515</td>\n",
       "      <td>-0.985033</td>\n",
       "      <td>-0.973886</td>\n",
       "      <td>-0.994035</td>\n",
       "      <td>-0.986531</td>\n",
       "      <td>-0.983616</td>\n",
       "      <td>-0.992352</td>\n",
       "      <td>-0.980498</td>\n",
       "      <td>-0.972271</td>\n",
       "      <td>-0.994944</td>\n",
       "      <td>-0.997569</td>\n",
       "      <td>-0.984085</td>\n",
       "      <td>-0.994335</td>\n",
       "      <td>-0.985276</td>\n",
       "      <td>-0.999864</td>\n",
       "      <td>-0.999666</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.990344</td>\n",
       "      <td>-0.994836</td>\n",
       "      <td>-0.994412</td>\n",
       "      <td>-0.712402</td>\n",
       "      <td>-0.644842</td>\n",
       "      <td>-0.838993</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.257549</td>\n",
       "      <td>0.097947</td>\n",
       "      <td>0.547151</td>\n",
       "      <td>0.377311</td>\n",
       "      <td>0.134092</td>\n",
       "      <td>0.273372</td>\n",
       "      <td>-0.091262</td>\n",
       "      <td>-0.484347</td>\n",
       "      <td>-0.782851</td>\n",
       "      <td>-0.999865</td>\n",
       "      <td>-0.999932</td>\n",
       "      <td>-0.999973</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.999930</td>\n",
       "      <td>-0.999959</td>\n",
       "      <td>-0.999929</td>\n",
       "      <td>-0.999985</td>\n",
       "      <td>-0.999863</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.999864</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>-0.999454</td>\n",
       "      <td>-0.999978</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>-0.998346</td>\n",
       "      <td>-0.998961</td>\n",
       "      <td>-0.999619</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.998388</td>\n",
       "      <td>-0.999643</td>\n",
       "      <td>-0.999973</td>\n",
       "      <td>-0.999955</td>\n",
       "      <td>-0.999976</td>\n",
       "      <td>-0.999906</td>\n",
       "      <td>-0.999985</td>\n",
       "      <td>-0.999937</td>\n",
       "      <td>-0.999751</td>\n",
       "      <td>-0.999072</td>\n",
       "      <td>-0.999928</td>\n",
       "      <td>-0.999952</td>\n",
       "      <td>-0.999906</td>\n",
       "      <td>-0.999893</td>\n",
       "      <td>-0.999444</td>\n",
       "      <td>-0.999941</td>\n",
       "      <td>-0.999959</td>\n",
       "      <td>-0.952155</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.974321</td>\n",
       "      <td>-0.925722</td>\n",
       "      <td>-0.952155</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>-0.973273</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>-0.793103</td>\n",
       "      <td>-0.088436</td>\n",
       "      <td>-0.436471</td>\n",
       "      <td>-0.796840</td>\n",
       "      <td>-0.993726</td>\n",
       "      <td>-0.993755</td>\n",
       "      <td>-0.991976</td>\n",
       "      <td>-0.993365</td>\n",
       "      <td>-0.988175</td>\n",
       "      <td>-0.993726</td>\n",
       "      <td>-0.999918</td>\n",
       "      <td>-0.991364</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.936508</td>\n",
       "      <td>0.346989</td>\n",
       "      <td>-0.516080</td>\n",
       "      <td>-0.802760</td>\n",
       "      <td>-0.980135</td>\n",
       "      <td>-0.961309</td>\n",
       "      <td>-0.973653</td>\n",
       "      <td>-0.952264</td>\n",
       "      <td>-0.989498</td>\n",
       "      <td>-0.980135</td>\n",
       "      <td>-0.999240</td>\n",
       "      <td>-0.992656</td>\n",
       "      <td>-0.701291</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.128989</td>\n",
       "      <td>0.586156</td>\n",
       "      <td>0.374605</td>\n",
       "      <td>-0.991990</td>\n",
       "      <td>-0.990697</td>\n",
       "      <td>-0.989941</td>\n",
       "      <td>-0.992448</td>\n",
       "      <td>-0.991048</td>\n",
       "      <td>-0.991990</td>\n",
       "      <td>-0.999937</td>\n",
       "      <td>-0.990458</td>\n",
       "      <td>-0.871306</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>-0.557851</td>\n",
       "      <td>-0.818409</td>\n",
       "      <td>0.849308</td>\n",
       "      <td>0.685845</td>\n",
       "      <td>0.822637</td>\n",
       "      <td>-0.981930</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999788</td>\n",
       "      <td>-0.998405</td>\n",
       "      <td>-0.999150</td>\n",
       "      <td>-0.977866</td>\n",
       "      <td>-0.948225</td>\n",
       "      <td>-0.714892</td>\n",
       "      <td>-0.500930</td>\n",
       "      <td>-0.570979</td>\n",
       "      <td>0.611627</td>\n",
       "      <td>-0.329549</td>\n",
       "      <td>0.284213</td>\n",
       "      <td>0.284595</td>\n",
       "      <td>0.115705</td>\n",
       "      <td>-0.090963</td>\n",
       "      <td>0.294310</td>\n",
       "      <td>-0.281211</td>\n",
       "      <td>0.085988</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.016657</td>\n",
       "      <td>-0.220643</td>\n",
       "      <td>-0.013429</td>\n",
       "      <td>-0.072692</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.966561</td>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.997411</td>\n",
       "      <td>-0.989447</td>\n",
       "      <td>-0.931639</td>\n",
       "      <td>-0.997884</td>\n",
       "      <td>-0.989614</td>\n",
       "      <td>-0.933240</td>\n",
       "      <td>0.892060</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>0.984520</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>0.907829</td>\n",
       "      <td>-0.970583</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.999188</td>\n",
       "      <td>-0.990029</td>\n",
       "      <td>-0.941685</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.210494</td>\n",
       "      <td>-0.410056</td>\n",
       "      <td>0.413856</td>\n",
       "      <td>-0.417567</td>\n",
       "      <td>0.421325</td>\n",
       "      <td>-0.196359</td>\n",
       "      <td>0.125345</td>\n",
       "      <td>-0.105568</td>\n",
       "      <td>0.109090</td>\n",
       "      <td>-0.833882</td>\n",
       "      <td>0.834271</td>\n",
       "      <td>-0.834184</td>\n",
       "      <td>0.830464</td>\n",
       "      <td>-0.831284</td>\n",
       "      <td>-0.865711</td>\n",
       "      <td>0.974386</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.029377</td>\n",
       "      <td>-0.995548</td>\n",
       "      <td>-0.981064</td>\n",
       "      <td>-0.991846</td>\n",
       "      <td>-0.995632</td>\n",
       "      <td>-0.978938</td>\n",
       "      <td>-0.991277</td>\n",
       "      <td>-0.994545</td>\n",
       "      <td>-0.979068</td>\n",
       "      <td>-0.992257</td>\n",
       "      <td>0.992577</td>\n",
       "      <td>0.991808</td>\n",
       "      <td>0.988539</td>\n",
       "      <td>-0.991394</td>\n",
       "      <td>-0.999960</td>\n",
       "      <td>-0.999640</td>\n",
       "      <td>-0.999845</td>\n",
       "      <td>-0.993863</td>\n",
       "      <td>-0.979435</td>\n",
       "      <td>-0.993384</td>\n",
       "      <td>-0.875096</td>\n",
       "      <td>-0.655362</td>\n",
       "      <td>-0.767381</td>\n",
       "      <td>0.489662</td>\n",
       "      <td>0.070997</td>\n",
       "      <td>0.362714</td>\n",
       "      <td>0.527303</td>\n",
       "      <td>0.149396</td>\n",
       "      <td>0.062925</td>\n",
       "      <td>0.370493</td>\n",
       "      <td>0.413548</td>\n",
       "      <td>0.122216</td>\n",
       "      <td>0.180613</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>0.166573</td>\n",
       "      <td>-0.208772</td>\n",
       "      <td>0.084104</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>-0.016112</td>\n",
       "      <td>-0.083894</td>\n",
       "      <td>0.100584</td>\n",
       "      <td>-0.983120</td>\n",
       "      <td>-0.989046</td>\n",
       "      <td>-0.989121</td>\n",
       "      <td>-0.986890</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>-0.989185</td>\n",
       "      <td>-0.864904</td>\n",
       "      <td>-0.953560</td>\n",
       "      <td>-0.745870</td>\n",
       "      <td>0.833721</td>\n",
       "      <td>0.908110</td>\n",
       "      <td>0.828935</td>\n",
       "      <td>-0.980613</td>\n",
       "      <td>-0.999756</td>\n",
       "      <td>-0.999897</td>\n",
       "      <td>-0.999822</td>\n",
       "      <td>-0.992833</td>\n",
       "      <td>-0.989345</td>\n",
       "      <td>-0.990240</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>-0.531157</td>\n",
       "      <td>-0.177445</td>\n",
       "      <td>-0.387681</td>\n",
       "      <td>0.179138</td>\n",
       "      <td>0.210789</td>\n",
       "      <td>-0.140260</td>\n",
       "      <td>-0.047032</td>\n",
       "      <td>-0.064949</td>\n",
       "      <td>0.117687</td>\n",
       "      <td>0.081691</td>\n",
       "      <td>0.042364</td>\n",
       "      <td>-0.149928</td>\n",
       "      <td>0.292619</td>\n",
       "      <td>-0.149429</td>\n",
       "      <td>0.046721</td>\n",
       "      <td>-0.256929</td>\n",
       "      <td>0.169395</td>\n",
       "      <td>-0.110503</td>\n",
       "      <td>-0.044819</td>\n",
       "      <td>-0.059243</td>\n",
       "      <td>-0.989873</td>\n",
       "      <td>-0.997293</td>\n",
       "      <td>-0.993851</td>\n",
       "      <td>-0.989876</td>\n",
       "      <td>-0.997492</td>\n",
       "      <td>-0.993778</td>\n",
       "      <td>-0.991947</td>\n",
       "      <td>-0.997717</td>\n",
       "      <td>-0.994921</td>\n",
       "      <td>0.990486</td>\n",
       "      <td>0.997122</td>\n",
       "      <td>0.994503</td>\n",
       "      <td>-0.995298</td>\n",
       "      <td>-0.999908</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.990742</td>\n",
       "      <td>-0.997301</td>\n",
       "      <td>-0.993808</td>\n",
       "      <td>-0.600945</td>\n",
       "      <td>-0.748247</td>\n",
       "      <td>-0.608932</td>\n",
       "      <td>-0.193308</td>\n",
       "      <td>-0.067406</td>\n",
       "      <td>0.185619</td>\n",
       "      <td>0.041522</td>\n",
       "      <td>0.072353</td>\n",
       "      <td>-0.035378</td>\n",
       "      <td>0.177606</td>\n",
       "      <td>0.027498</td>\n",
       "      <td>0.182703</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>0.253251</td>\n",
       "      <td>0.132334</td>\n",
       "      <td>0.293855</td>\n",
       "      <td>-0.018075</td>\n",
       "      <td>-0.343337</td>\n",
       "      <td>-0.979289</td>\n",
       "      <td>-0.976057</td>\n",
       "      <td>-0.978247</td>\n",
       "      <td>-0.978711</td>\n",
       "      <td>-0.995333</td>\n",
       "      <td>-0.979289</td>\n",
       "      <td>-0.999488</td>\n",
       "      <td>-0.981248</td>\n",
       "      <td>-0.441876</td>\n",
       "      <td>0.081569</td>\n",
       "      <td>-0.109366</td>\n",
       "      <td>0.311758</td>\n",
       "      <td>-0.411675</td>\n",
       "      <td>-0.979289</td>\n",
       "      <td>-0.976057</td>\n",
       "      <td>-0.978247</td>\n",
       "      <td>-0.978711</td>\n",
       "      <td>-0.995333</td>\n",
       "      <td>-0.979289</td>\n",
       "      <td>-0.999488</td>\n",
       "      <td>-0.981248</td>\n",
       "      <td>-0.441876</td>\n",
       "      <td>0.081569</td>\n",
       "      <td>-0.109366</td>\n",
       "      <td>0.311758</td>\n",
       "      <td>-0.411675</td>\n",
       "      <td>-0.991253</td>\n",
       "      <td>-0.991694</td>\n",
       "      <td>-0.992716</td>\n",
       "      <td>-0.988661</td>\n",
       "      <td>-0.991208</td>\n",
       "      <td>-0.991253</td>\n",
       "      <td>-0.999845</td>\n",
       "      <td>-0.993485</td>\n",
       "      <td>-0.819928</td>\n",
       "      <td>0.458812</td>\n",
       "      <td>-0.244941</td>\n",
       "      <td>0.056139</td>\n",
       "      <td>-0.458346</td>\n",
       "      <td>-0.980683</td>\n",
       "      <td>-0.983754</td>\n",
       "      <td>-0.982003</td>\n",
       "      <td>-0.984715</td>\n",
       "      <td>-0.991554</td>\n",
       "      <td>-0.980683</td>\n",
       "      <td>-0.999725</td>\n",
       "      <td>-0.982857</td>\n",
       "      <td>-0.192899</td>\n",
       "      <td>-0.225317</td>\n",
       "      <td>-0.017060</td>\n",
       "      <td>0.155777</td>\n",
       "      <td>0.082575</td>\n",
       "      <td>-0.995123</td>\n",
       "      <td>-0.996102</td>\n",
       "      <td>-0.995839</td>\n",
       "      <td>-0.996545</td>\n",
       "      <td>-0.992006</td>\n",
       "      <td>-0.995123</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.994819</td>\n",
       "      <td>-0.730722</td>\n",
       "      <td>0.209334</td>\n",
       "      <td>-0.178113</td>\n",
       "      <td>-0.103084</td>\n",
       "      <td>-0.043824</td>\n",
       "      <td>-0.997451</td>\n",
       "      <td>-0.976852</td>\n",
       "      <td>-0.973523</td>\n",
       "      <td>-0.998680</td>\n",
       "      <td>-0.974930</td>\n",
       "      <td>-0.955438</td>\n",
       "      <td>-0.997890</td>\n",
       "      <td>-0.976924</td>\n",
       "      <td>-0.968377</td>\n",
       "      <td>-0.999372</td>\n",
       "      <td>-0.973770</td>\n",
       "      <td>-0.948777</td>\n",
       "      <td>-0.998281</td>\n",
       "      <td>-0.992721</td>\n",
       "      <td>-0.989514</td>\n",
       "      <td>-0.985812</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999450</td>\n",
       "      <td>-0.998569</td>\n",
       "      <td>-0.994865</td>\n",
       "      <td>-0.980784</td>\n",
       "      <td>-0.985775</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.904748</td>\n",
       "      <td>-0.758409</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.271309</td>\n",
       "      <td>0.042864</td>\n",
       "      <td>-0.014310</td>\n",
       "      <td>-0.692541</td>\n",
       "      <td>-0.954047</td>\n",
       "      <td>-0.049709</td>\n",
       "      <td>-0.331974</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>-0.289001</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.999919</td>\n",
       "      <td>-0.999866</td>\n",
       "      <td>-0.999965</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.999914</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.999417</td>\n",
       "      <td>-0.999813</td>\n",
       "      <td>-0.999569</td>\n",
       "      <td>-0.999874</td>\n",
       "      <td>-0.999549</td>\n",
       "      <td>-0.999737</td>\n",
       "      <td>-0.999566</td>\n",
       "      <td>-0.999905</td>\n",
       "      <td>-0.999474</td>\n",
       "      <td>-0.999554</td>\n",
       "      <td>-0.999602</td>\n",
       "      <td>-0.999695</td>\n",
       "      <td>-0.999444</td>\n",
       "      <td>-0.999804</td>\n",
       "      <td>-0.998235</td>\n",
       "      <td>-0.999769</td>\n",
       "      <td>-0.999692</td>\n",
       "      <td>-0.999875</td>\n",
       "      <td>-0.999666</td>\n",
       "      <td>-0.999448</td>\n",
       "      <td>-0.998930</td>\n",
       "      <td>-0.998754</td>\n",
       "      <td>-0.998546</td>\n",
       "      <td>-0.999792</td>\n",
       "      <td>-0.999631</td>\n",
       "      <td>-0.998878</td>\n",
       "      <td>-0.998553</td>\n",
       "      <td>-0.999822</td>\n",
       "      <td>-0.995032</td>\n",
       "      <td>-0.981311</td>\n",
       "      <td>-0.989740</td>\n",
       "      <td>-0.996652</td>\n",
       "      <td>-0.982084</td>\n",
       "      <td>-0.992627</td>\n",
       "      <td>-0.994977</td>\n",
       "      <td>-0.982929</td>\n",
       "      <td>-0.991641</td>\n",
       "      <td>-0.997425</td>\n",
       "      <td>-0.984923</td>\n",
       "      <td>-0.993187</td>\n",
       "      <td>-0.997917</td>\n",
       "      <td>-0.982519</td>\n",
       "      <td>-0.986838</td>\n",
       "      <td>-0.989851</td>\n",
       "      <td>-0.999960</td>\n",
       "      <td>-0.999640</td>\n",
       "      <td>-0.999847</td>\n",
       "      <td>-0.992843</td>\n",
       "      <td>-0.985221</td>\n",
       "      <td>-0.991049</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.608514</td>\n",
       "      <td>-0.053676</td>\n",
       "      <td>0.063148</td>\n",
       "      <td>-0.630305</td>\n",
       "      <td>-0.910394</td>\n",
       "      <td>-0.414424</td>\n",
       "      <td>-0.850586</td>\n",
       "      <td>-0.655535</td>\n",
       "      <td>-0.915987</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999980</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999910</td>\n",
       "      <td>-0.999814</td>\n",
       "      <td>-0.999920</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>-0.999987</td>\n",
       "      <td>-0.999956</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>-0.999914</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.999906</td>\n",
       "      <td>-0.999861</td>\n",
       "      <td>-0.999827</td>\n",
       "      <td>-0.999456</td>\n",
       "      <td>-0.999830</td>\n",
       "      <td>-0.999609</td>\n",
       "      <td>-0.999685</td>\n",
       "      <td>-0.999576</td>\n",
       "      <td>-0.999937</td>\n",
       "      <td>-0.999817</td>\n",
       "      <td>-0.999532</td>\n",
       "      <td>-0.999595</td>\n",
       "      <td>-0.999626</td>\n",
       "      <td>-0.999630</td>\n",
       "      <td>-0.999759</td>\n",
       "      <td>-0.999859</td>\n",
       "      <td>-0.999846</td>\n",
       "      <td>-0.999795</td>\n",
       "      <td>-0.999801</td>\n",
       "      <td>-0.999819</td>\n",
       "      <td>-0.999769</td>\n",
       "      <td>-0.999637</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.999852</td>\n",
       "      <td>-0.999827</td>\n",
       "      <td>-0.999800</td>\n",
       "      <td>-0.999651</td>\n",
       "      <td>-0.999835</td>\n",
       "      <td>-0.999827</td>\n",
       "      <td>-0.977387</td>\n",
       "      <td>-0.992530</td>\n",
       "      <td>-0.989606</td>\n",
       "      <td>-0.984904</td>\n",
       "      <td>-0.987168</td>\n",
       "      <td>-0.989785</td>\n",
       "      <td>-0.979361</td>\n",
       "      <td>-0.991837</td>\n",
       "      <td>-0.987965</td>\n",
       "      <td>-0.987354</td>\n",
       "      <td>-0.984786</td>\n",
       "      <td>-0.990151</td>\n",
       "      <td>-0.986892</td>\n",
       "      <td>-0.999054</td>\n",
       "      <td>-0.994414</td>\n",
       "      <td>-0.986869</td>\n",
       "      <td>-0.999825</td>\n",
       "      <td>-0.999911</td>\n",
       "      <td>-0.999892</td>\n",
       "      <td>-0.987099</td>\n",
       "      <td>-0.995564</td>\n",
       "      <td>-0.987254</td>\n",
       "      <td>-0.611112</td>\n",
       "      <td>-0.764603</td>\n",
       "      <td>-0.751080</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.048167</td>\n",
       "      <td>-0.401608</td>\n",
       "      <td>-0.068178</td>\n",
       "      <td>-0.458553</td>\n",
       "      <td>-0.797014</td>\n",
       "      <td>0.387569</td>\n",
       "      <td>0.148665</td>\n",
       "      <td>-0.156909</td>\n",
       "      <td>-0.451776</td>\n",
       "      <td>-0.999851</td>\n",
       "      <td>-0.999794</td>\n",
       "      <td>-0.999913</td>\n",
       "      <td>-0.999918</td>\n",
       "      <td>-0.999896</td>\n",
       "      <td>-0.999885</td>\n",
       "      <td>-0.999784</td>\n",
       "      <td>-0.999782</td>\n",
       "      <td>-0.999830</td>\n",
       "      <td>-0.999899</td>\n",
       "      <td>-0.999883</td>\n",
       "      <td>-0.999783</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>-0.999908</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999985</td>\n",
       "      <td>-0.999980</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999897</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-0.999903</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999909</td>\n",
       "      <td>-0.999959</td>\n",
       "      <td>-0.999928</td>\n",
       "      <td>-0.999966</td>\n",
       "      <td>-0.999985</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999902</td>\n",
       "      <td>-0.999918</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.999894</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.980857</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.978226</td>\n",
       "      <td>-0.986911</td>\n",
       "      <td>-0.980857</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>-0.984479</td>\n",
       "      <td>-0.816674</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.044150</td>\n",
       "      <td>-0.122040</td>\n",
       "      <td>-0.449522</td>\n",
       "      <td>-0.990335</td>\n",
       "      <td>-0.991960</td>\n",
       "      <td>-0.989732</td>\n",
       "      <td>-0.994489</td>\n",
       "      <td>-0.989549</td>\n",
       "      <td>-0.990335</td>\n",
       "      <td>-0.999867</td>\n",
       "      <td>-0.991134</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.841270</td>\n",
       "      <td>0.532061</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.900160</td>\n",
       "      <td>-0.988296</td>\n",
       "      <td>-0.983322</td>\n",
       "      <td>-0.982659</td>\n",
       "      <td>-0.986321</td>\n",
       "      <td>-0.991829</td>\n",
       "      <td>-0.988296</td>\n",
       "      <td>-0.999811</td>\n",
       "      <td>-0.993979</td>\n",
       "      <td>-0.720683</td>\n",
       "      <td>-0.948718</td>\n",
       "      <td>-0.271958</td>\n",
       "      <td>-0.336310</td>\n",
       "      <td>-0.720015</td>\n",
       "      <td>-0.995854</td>\n",
       "      <td>-0.996399</td>\n",
       "      <td>-0.995442</td>\n",
       "      <td>-0.996866</td>\n",
       "      <td>-0.994440</td>\n",
       "      <td>-0.995854</td>\n",
       "      <td>-0.999981</td>\n",
       "      <td>-0.994544</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.158075</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>-0.557851</td>\n",
       "      <td>-0.818409</td>\n",
       "      <td>0.843609</td>\n",
       "      <td>0.682401</td>\n",
       "      <td>0.839344</td>\n",
       "      <td>-0.983478</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999660</td>\n",
       "      <td>-0.999470</td>\n",
       "      <td>-0.997130</td>\n",
       "      <td>-0.964810</td>\n",
       "      <td>-0.974675</td>\n",
       "      <td>-0.592235</td>\n",
       "      <td>-0.485821</td>\n",
       "      <td>-0.570979</td>\n",
       "      <td>0.273025</td>\n",
       "      <td>-0.086309</td>\n",
       "      <td>0.337202</td>\n",
       "      <td>-0.164739</td>\n",
       "      <td>0.017150</td>\n",
       "      <td>-0.074507</td>\n",
       "      <td>0.342256</td>\n",
       "      <td>-0.332564</td>\n",
       "      <td>0.239281</td>\n",
       "      <td>-0.136204</td>\n",
       "      <td>0.173863</td>\n",
       "      <td>-0.299493</td>\n",
       "      <td>-0.124698</td>\n",
       "      <td>-0.181105</td>\n",
       "      <td>0.608900</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.999574</td>\n",
       "      <td>-0.992866</td>\n",
       "      <td>-0.992917</td>\n",
       "      <td>-0.999635</td>\n",
       "      <td>-0.992605</td>\n",
       "      <td>-0.992934</td>\n",
       "      <td>0.892401</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>0.986770</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>0.908668</td>\n",
       "      <td>-0.970368</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.999679</td>\n",
       "      <td>-0.992104</td>\n",
       "      <td>-0.992619</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.926776</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>-0.056728</td>\n",
       "      <td>0.085533</td>\n",
       "      <td>-0.329023</td>\n",
       "      <td>0.270500</td>\n",
       "      <td>-0.254490</td>\n",
       "      <td>0.257598</td>\n",
       "      <td>-0.705039</td>\n",
       "      <td>0.714392</td>\n",
       "      <td>-0.723299</td>\n",
       "      <td>0.728755</td>\n",
       "      <td>-0.181090</td>\n",
       "      <td>0.337936</td>\n",
       "      <td>0.643417</td>\n",
       "      <td>0.073636</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>-0.990743</td>\n",
       "      <td>-0.980956</td>\n",
       "      <td>-0.989687</td>\n",
       "      <td>-0.990933</td>\n",
       "      <td>-0.979300</td>\n",
       "      <td>-0.987238</td>\n",
       "      <td>-0.987077</td>\n",
       "      <td>-0.979068</td>\n",
       "      <td>-0.992257</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>0.991808</td>\n",
       "      <td>0.988539</td>\n",
       "      <td>-0.988148</td>\n",
       "      <td>-0.999894</td>\n",
       "      <td>-0.999636</td>\n",
       "      <td>-0.999795</td>\n",
       "      <td>-0.987846</td>\n",
       "      <td>-0.980145</td>\n",
       "      <td>-0.981911</td>\n",
       "      <td>-0.753629</td>\n",
       "      <td>-0.673274</td>\n",
       "      <td>-0.747107</td>\n",
       "      <td>0.265225</td>\n",
       "      <td>0.188395</td>\n",
       "      <td>0.464583</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.082665</td>\n",
       "      <td>-0.004622</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>0.437623</td>\n",
       "      <td>0.257891</td>\n",
       "      <td>0.070030</td>\n",
       "      <td>0.186973</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>-0.120105</td>\n",
       "      <td>-0.110026</td>\n",
       "      <td>-0.039953</td>\n",
       "      <td>-0.031698</td>\n",
       "      <td>-0.102335</td>\n",
       "      <td>0.096127</td>\n",
       "      <td>-0.976292</td>\n",
       "      <td>-0.993552</td>\n",
       "      <td>-0.986379</td>\n",
       "      <td>-0.974922</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>-0.985786</td>\n",
       "      <td>-0.864904</td>\n",
       "      <td>-0.959049</td>\n",
       "      <td>-0.743277</td>\n",
       "      <td>0.833721</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>0.828935</td>\n",
       "      <td>-0.976280</td>\n",
       "      <td>-0.999693</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>-0.999822</td>\n",
       "      <td>-0.972354</td>\n",
       "      <td>-0.995144</td>\n",
       "      <td>-0.986831</td>\n",
       "      <td>-0.260943</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.248371</td>\n",
       "      <td>-0.437156</td>\n",
       "      <td>0.238981</td>\n",
       "      <td>0.145238</td>\n",
       "      <td>-0.113917</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>-0.127879</td>\n",
       "      <td>0.114924</td>\n",
       "      <td>0.125398</td>\n",
       "      <td>0.112092</td>\n",
       "      <td>-0.165645</td>\n",
       "      <td>0.134554</td>\n",
       "      <td>0.184349</td>\n",
       "      <td>-0.010130</td>\n",
       "      <td>0.043312</td>\n",
       "      <td>-0.350646</td>\n",
       "      <td>-0.108486</td>\n",
       "      <td>-0.042410</td>\n",
       "      <td>-0.055829</td>\n",
       "      <td>-0.988462</td>\n",
       "      <td>-0.995632</td>\n",
       "      <td>-0.991532</td>\n",
       "      <td>-0.987868</td>\n",
       "      <td>-0.995725</td>\n",
       "      <td>-0.991596</td>\n",
       "      <td>-0.993359</td>\n",
       "      <td>-0.993800</td>\n",
       "      <td>-0.988963</td>\n",
       "      <td>0.989290</td>\n",
       "      <td>0.997122</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>-0.993415</td>\n",
       "      <td>-0.999887</td>\n",
       "      <td>-0.999980</td>\n",
       "      <td>-0.999916</td>\n",
       "      <td>-0.987130</td>\n",
       "      <td>-0.995428</td>\n",
       "      <td>-0.992776</td>\n",
       "      <td>-0.543635</td>\n",
       "      <td>-0.672957</td>\n",
       "      <td>-0.588410</td>\n",
       "      <td>-0.241151</td>\n",
       "      <td>-0.011377</td>\n",
       "      <td>0.116134</td>\n",
       "      <td>0.089630</td>\n",
       "      <td>0.095986</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.095126</td>\n",
       "      <td>0.252887</td>\n",
       "      <td>0.181649</td>\n",
       "      <td>-0.169308</td>\n",
       "      <td>0.132009</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.193329</td>\n",
       "      <td>0.073718</td>\n",
       "      <td>-0.314858</td>\n",
       "      <td>-0.983703</td>\n",
       "      <td>-0.988020</td>\n",
       "      <td>-0.988327</td>\n",
       "      <td>-0.986496</td>\n",
       "      <td>-0.995333</td>\n",
       "      <td>-0.983703</td>\n",
       "      <td>-0.999682</td>\n",
       "      <td>-0.985767</td>\n",
       "      <td>-0.599939</td>\n",
       "      <td>0.038049</td>\n",
       "      <td>-0.074212</td>\n",
       "      <td>0.254076</td>\n",
       "      <td>-0.296130</td>\n",
       "      <td>-0.983703</td>\n",
       "      <td>-0.988020</td>\n",
       "      <td>-0.988327</td>\n",
       "      <td>-0.986496</td>\n",
       "      <td>-0.995333</td>\n",
       "      <td>-0.983703</td>\n",
       "      <td>-0.999682</td>\n",
       "      <td>-0.985767</td>\n",
       "      <td>-0.599939</td>\n",
       "      <td>0.038049</td>\n",
       "      <td>-0.074212</td>\n",
       "      <td>0.254076</td>\n",
       "      <td>-0.296130</td>\n",
       "      <td>-0.988531</td>\n",
       "      <td>-0.990397</td>\n",
       "      <td>-0.990650</td>\n",
       "      <td>-0.988661</td>\n",
       "      <td>-0.993012</td>\n",
       "      <td>-0.988531</td>\n",
       "      <td>-0.999790</td>\n",
       "      <td>-0.989984</td>\n",
       "      <td>-0.794884</td>\n",
       "      <td>0.649704</td>\n",
       "      <td>-0.260088</td>\n",
       "      <td>-0.128416</td>\n",
       "      <td>-0.520541</td>\n",
       "      <td>-0.976317</td>\n",
       "      <td>-0.986051</td>\n",
       "      <td>-0.984458</td>\n",
       "      <td>-0.984715</td>\n",
       "      <td>-0.966193</td>\n",
       "      <td>-0.976317</td>\n",
       "      <td>-0.999641</td>\n",
       "      <td>-0.983454</td>\n",
       "      <td>-0.222829</td>\n",
       "      <td>-0.226831</td>\n",
       "      <td>0.059681</td>\n",
       "      <td>0.061476</td>\n",
       "      <td>0.041702</td>\n",
       "      <td>-0.993403</td>\n",
       "      <td>-0.995091</td>\n",
       "      <td>-0.994859</td>\n",
       "      <td>-0.995360</td>\n",
       "      <td>-0.997652</td>\n",
       "      <td>-0.993403</td>\n",
       "      <td>-0.999955</td>\n",
       "      <td>-0.993988</td>\n",
       "      <td>-0.662914</td>\n",
       "      <td>0.328031</td>\n",
       "      <td>-0.154560</td>\n",
       "      <td>-0.220587</td>\n",
       "      <td>-0.107514</td>\n",
       "      <td>-0.993594</td>\n",
       "      <td>-0.972511</td>\n",
       "      <td>-0.983304</td>\n",
       "      <td>-0.996313</td>\n",
       "      <td>-0.965506</td>\n",
       "      <td>-0.977049</td>\n",
       "      <td>-0.994097</td>\n",
       "      <td>-0.971687</td>\n",
       "      <td>-0.982169</td>\n",
       "      <td>-0.998158</td>\n",
       "      <td>-0.963072</td>\n",
       "      <td>-0.968596</td>\n",
       "      <td>-0.997094</td>\n",
       "      <td>-0.989924</td>\n",
       "      <td>-0.990886</td>\n",
       "      <td>-0.985821</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999137</td>\n",
       "      <td>-0.999434</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.977242</td>\n",
       "      <td>-0.981302</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.815786</td>\n",
       "      <td>-0.813513</td>\n",
       "      <td>-0.935484</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.124531</td>\n",
       "      <td>-0.064611</td>\n",
       "      <td>0.082677</td>\n",
       "      <td>-0.727227</td>\n",
       "      <td>-0.965419</td>\n",
       "      <td>0.163063</td>\n",
       "      <td>-0.092153</td>\n",
       "      <td>-0.044937</td>\n",
       "      <td>-0.288366</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.999815</td>\n",
       "      <td>-0.999847</td>\n",
       "      <td>-0.999939</td>\n",
       "      <td>-0.999922</td>\n",
       "      <td>-0.999923</td>\n",
       "      <td>-0.999997</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999802</td>\n",
       "      <td>-0.999948</td>\n",
       "      <td>-0.999948</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.999875</td>\n",
       "      <td>-0.999006</td>\n",
       "      <td>-0.999715</td>\n",
       "      <td>-0.999658</td>\n",
       "      <td>-0.999817</td>\n",
       "      <td>-0.999636</td>\n",
       "      <td>-0.999679</td>\n",
       "      <td>-0.999616</td>\n",
       "      <td>-0.999880</td>\n",
       "      <td>-0.999108</td>\n",
       "      <td>-0.999624</td>\n",
       "      <td>-0.999643</td>\n",
       "      <td>-0.999715</td>\n",
       "      <td>-0.999126</td>\n",
       "      <td>-0.999775</td>\n",
       "      <td>-0.999388</td>\n",
       "      <td>-0.999725</td>\n",
       "      <td>-0.999718</td>\n",
       "      <td>-0.999798</td>\n",
       "      <td>-0.999753</td>\n",
       "      <td>-0.999629</td>\n",
       "      <td>-0.999686</td>\n",
       "      <td>-0.999912</td>\n",
       "      <td>-0.999453</td>\n",
       "      <td>-0.999781</td>\n",
       "      <td>-0.999749</td>\n",
       "      <td>-0.999760</td>\n",
       "      <td>-0.999434</td>\n",
       "      <td>-0.999801</td>\n",
       "      <td>-0.990994</td>\n",
       "      <td>-0.981642</td>\n",
       "      <td>-0.987566</td>\n",
       "      <td>-0.991249</td>\n",
       "      <td>-0.981415</td>\n",
       "      <td>-0.990416</td>\n",
       "      <td>-0.987751</td>\n",
       "      <td>-0.981091</td>\n",
       "      <td>-0.987723</td>\n",
       "      <td>-0.995163</td>\n",
       "      <td>-0.985351</td>\n",
       "      <td>-0.993912</td>\n",
       "      <td>-0.997482</td>\n",
       "      <td>-0.998571</td>\n",
       "      <td>-0.997554</td>\n",
       "      <td>-0.987237</td>\n",
       "      <td>-0.999894</td>\n",
       "      <td>-0.999637</td>\n",
       "      <td>-0.999795</td>\n",
       "      <td>-0.981817</td>\n",
       "      <td>-0.984765</td>\n",
       "      <td>-0.982364</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.115434</td>\n",
       "      <td>-0.193436</td>\n",
       "      <td>0.038254</td>\n",
       "      <td>-0.594759</td>\n",
       "      <td>-0.923541</td>\n",
       "      <td>-0.528934</td>\n",
       "      <td>-0.912985</td>\n",
       "      <td>-0.803407</td>\n",
       "      <td>-0.980133</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999827</td>\n",
       "      <td>-0.999841</td>\n",
       "      <td>-0.999922</td>\n",
       "      <td>-0.999906</td>\n",
       "      <td>-0.999874</td>\n",
       "      <td>-0.999997</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999804</td>\n",
       "      <td>-0.999923</td>\n",
       "      <td>-0.999875</td>\n",
       "      <td>-0.999909</td>\n",
       "      <td>-0.999843</td>\n",
       "      <td>-0.999820</td>\n",
       "      <td>-0.999744</td>\n",
       "      <td>-0.999559</td>\n",
       "      <td>-0.999839</td>\n",
       "      <td>-0.999667</td>\n",
       "      <td>-0.999627</td>\n",
       "      <td>-0.999704</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999732</td>\n",
       "      <td>-0.999611</td>\n",
       "      <td>-0.999618</td>\n",
       "      <td>-0.999744</td>\n",
       "      <td>-0.999613</td>\n",
       "      <td>-0.999773</td>\n",
       "      <td>-0.999871</td>\n",
       "      <td>-0.999784</td>\n",
       "      <td>-0.999740</td>\n",
       "      <td>-0.999787</td>\n",
       "      <td>-0.999772</td>\n",
       "      <td>-0.999626</td>\n",
       "      <td>-0.999487</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999803</td>\n",
       "      <td>-0.999792</td>\n",
       "      <td>-0.999721</td>\n",
       "      <td>-0.999514</td>\n",
       "      <td>-0.999775</td>\n",
       "      <td>-0.999787</td>\n",
       "      <td>-0.975433</td>\n",
       "      <td>-0.993715</td>\n",
       "      <td>-0.986756</td>\n",
       "      <td>-0.976642</td>\n",
       "      <td>-0.993399</td>\n",
       "      <td>-0.987328</td>\n",
       "      <td>-0.975609</td>\n",
       "      <td>-0.993707</td>\n",
       "      <td>-0.985030</td>\n",
       "      <td>-0.972901</td>\n",
       "      <td>-0.994986</td>\n",
       "      <td>-0.991283</td>\n",
       "      <td>-0.988312</td>\n",
       "      <td>-0.997233</td>\n",
       "      <td>-0.993636</td>\n",
       "      <td>-0.986009</td>\n",
       "      <td>-0.999673</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.999846</td>\n",
       "      <td>-0.985536</td>\n",
       "      <td>-0.995392</td>\n",
       "      <td>-0.992551</td>\n",
       "      <td>-0.590987</td>\n",
       "      <td>-0.808287</td>\n",
       "      <td>-0.751080</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.870968</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.216685</td>\n",
       "      <td>-0.017264</td>\n",
       "      <td>-0.110720</td>\n",
       "      <td>0.090519</td>\n",
       "      <td>-0.244691</td>\n",
       "      <td>-0.429272</td>\n",
       "      <td>-0.812639</td>\n",
       "      <td>-0.391991</td>\n",
       "      <td>-0.767482</td>\n",
       "      <td>-0.999680</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>-0.999915</td>\n",
       "      <td>-0.999932</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>-0.999842</td>\n",
       "      <td>-0.999864</td>\n",
       "      <td>-0.999862</td>\n",
       "      <td>-0.999674</td>\n",
       "      <td>-0.999906</td>\n",
       "      <td>-0.999831</td>\n",
       "      <td>-0.999863</td>\n",
       "      <td>-0.999676</td>\n",
       "      <td>-0.999903</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999973</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>-0.999987</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999967</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999961</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999870</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.999957</td>\n",
       "      <td>-0.999952</td>\n",
       "      <td>-0.999909</td>\n",
       "      <td>-0.999889</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>-0.999920</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.999850</td>\n",
       "      <td>-0.999956</td>\n",
       "      <td>-0.987795</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.993062</td>\n",
       "      <td>-0.989836</td>\n",
       "      <td>-0.987795</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>-0.989237</td>\n",
       "      <td>-0.907014</td>\n",
       "      <td>-0.862069</td>\n",
       "      <td>0.257899</td>\n",
       "      <td>-0.618725</td>\n",
       "      <td>-0.879685</td>\n",
       "      <td>-0.989280</td>\n",
       "      <td>-0.990867</td>\n",
       "      <td>-0.987274</td>\n",
       "      <td>-0.993179</td>\n",
       "      <td>-0.999890</td>\n",
       "      <td>-0.989280</td>\n",
       "      <td>-0.999845</td>\n",
       "      <td>-0.986658</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.904762</td>\n",
       "      <td>0.660795</td>\n",
       "      <td>-0.724697</td>\n",
       "      <td>-0.928539</td>\n",
       "      <td>-0.989255</td>\n",
       "      <td>-0.986028</td>\n",
       "      <td>-0.984274</td>\n",
       "      <td>-0.990979</td>\n",
       "      <td>-0.995703</td>\n",
       "      <td>-0.989255</td>\n",
       "      <td>-0.999854</td>\n",
       "      <td>-0.993238</td>\n",
       "      <td>-0.736521</td>\n",
       "      <td>-0.794872</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>-0.535352</td>\n",
       "      <td>-0.871914</td>\n",
       "      <td>-0.995031</td>\n",
       "      <td>-0.995127</td>\n",
       "      <td>-0.994640</td>\n",
       "      <td>-0.996060</td>\n",
       "      <td>-0.995866</td>\n",
       "      <td>-0.995031</td>\n",
       "      <td>-0.999973</td>\n",
       "      <td>-0.993755</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>-0.576159</td>\n",
       "      <td>-0.829711</td>\n",
       "      <td>0.843609</td>\n",
       "      <td>0.682401</td>\n",
       "      <td>0.837869</td>\n",
       "      <td>-0.986093</td>\n",
       "      <td>-0.999976</td>\n",
       "      <td>-0.999736</td>\n",
       "      <td>-0.999504</td>\n",
       "      <td>-0.997180</td>\n",
       "      <td>-0.983799</td>\n",
       "      <td>-0.986007</td>\n",
       "      <td>-0.627446</td>\n",
       "      <td>-0.850930</td>\n",
       "      <td>-0.911872</td>\n",
       "      <td>0.061436</td>\n",
       "      <td>0.074840</td>\n",
       "      <td>0.198204</td>\n",
       "      <td>-0.264307</td>\n",
       "      <td>0.072545</td>\n",
       "      <td>-0.155320</td>\n",
       "      <td>0.323154</td>\n",
       "      <td>-0.170813</td>\n",
       "      <td>0.294938</td>\n",
       "      <td>-0.306081</td>\n",
       "      <td>0.482148</td>\n",
       "      <td>-0.470129</td>\n",
       "      <td>-0.305693</td>\n",
       "      <td>-0.362654</td>\n",
       "      <td>0.507459</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.996646</td>\n",
       "      <td>-0.981393</td>\n",
       "      <td>-0.978476</td>\n",
       "      <td>-0.996457</td>\n",
       "      <td>-0.980962</td>\n",
       "      <td>-0.978456</td>\n",
       "      <td>0.893817</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>0.986821</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>0.910621</td>\n",
       "      <td>-0.969400</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.995976</td>\n",
       "      <td>-0.980663</td>\n",
       "      <td>-0.979779</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.596101</td>\n",
       "      <td>-0.064935</td>\n",
       "      <td>0.075427</td>\n",
       "      <td>-0.085823</td>\n",
       "      <td>0.096208</td>\n",
       "      <td>-0.295036</td>\n",
       "      <td>0.228310</td>\n",
       "      <td>-0.206281</td>\n",
       "      <td>0.204801</td>\n",
       "      <td>-0.385410</td>\n",
       "      <td>0.386373</td>\n",
       "      <td>-0.387120</td>\n",
       "      <td>0.385263</td>\n",
       "      <td>-0.991309</td>\n",
       "      <td>-0.968821</td>\n",
       "      <td>0.984256</td>\n",
       "      <td>0.077321</td>\n",
       "      <td>0.020058</td>\n",
       "      <td>-0.009865</td>\n",
       "      <td>-0.992697</td>\n",
       "      <td>-0.987553</td>\n",
       "      <td>-0.993498</td>\n",
       "      <td>-0.994266</td>\n",
       "      <td>-0.985717</td>\n",
       "      <td>-0.991483</td>\n",
       "      <td>-0.987077</td>\n",
       "      <td>-0.991786</td>\n",
       "      <td>-0.989769</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>0.992544</td>\n",
       "      <td>0.993218</td>\n",
       "      <td>-0.992868</td>\n",
       "      <td>-0.999924</td>\n",
       "      <td>-0.999803</td>\n",
       "      <td>-0.999883</td>\n",
       "      <td>-0.994678</td>\n",
       "      <td>-0.987033</td>\n",
       "      <td>-0.988896</td>\n",
       "      <td>-0.820804</td>\n",
       "      <td>-0.754968</td>\n",
       "      <td>-0.825279</td>\n",
       "      <td>0.122893</td>\n",
       "      <td>0.276419</td>\n",
       "      <td>0.457445</td>\n",
       "      <td>0.193414</td>\n",
       "      <td>0.102405</td>\n",
       "      <td>-0.099103</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.484244</td>\n",
       "      <td>0.357657</td>\n",
       "      <td>-0.187032</td>\n",
       "      <td>0.298069</td>\n",
       "      <td>0.451870</td>\n",
       "      <td>-0.127495</td>\n",
       "      <td>-0.083278</td>\n",
       "      <td>0.457060</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>-0.091386</td>\n",
       "      <td>0.085538</td>\n",
       "      <td>-0.991385</td>\n",
       "      <td>-0.992407</td>\n",
       "      <td>-0.987554</td>\n",
       "      <td>-0.991589</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>-0.989585</td>\n",
       "      <td>-0.885320</td>\n",
       "      <td>-0.956656</td>\n",
       "      <td>-0.743277</td>\n",
       "      <td>0.834164</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>0.826634</td>\n",
       "      <td>-0.982296</td>\n",
       "      <td>-0.999793</td>\n",
       "      <td>-0.999902</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>-0.991031</td>\n",
       "      <td>-0.994165</td>\n",
       "      <td>-0.994582</td>\n",
       "      <td>-0.930551</td>\n",
       "      <td>-0.826618</td>\n",
       "      <td>-0.543422</td>\n",
       "      <td>-0.165885</td>\n",
       "      <td>-0.012881</td>\n",
       "      <td>0.320055</td>\n",
       "      <td>-0.165114</td>\n",
       "      <td>0.044553</td>\n",
       "      <td>-0.125193</td>\n",
       "      <td>0.078321</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>0.193402</td>\n",
       "      <td>-0.207189</td>\n",
       "      <td>0.112457</td>\n",
       "      <td>0.202092</td>\n",
       "      <td>0.210194</td>\n",
       "      <td>0.141101</td>\n",
       "      <td>-0.725301</td>\n",
       "      <td>-0.091170</td>\n",
       "      <td>-0.036333</td>\n",
       "      <td>-0.060465</td>\n",
       "      <td>-0.991119</td>\n",
       "      <td>-0.996641</td>\n",
       "      <td>-0.993329</td>\n",
       "      <td>-0.991241</td>\n",
       "      <td>-0.996958</td>\n",
       "      <td>-0.994019</td>\n",
       "      <td>-0.993676</td>\n",
       "      <td>-0.993800</td>\n",
       "      <td>-0.988963</td>\n",
       "      <td>0.989290</td>\n",
       "      <td>0.998130</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>-0.995496</td>\n",
       "      <td>-0.999925</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.990909</td>\n",
       "      <td>-0.997078</td>\n",
       "      <td>-0.995405</td>\n",
       "      <td>-0.562031</td>\n",
       "      <td>-0.731332</td>\n",
       "      <td>-0.661434</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>-0.137571</td>\n",
       "      <td>0.125965</td>\n",
       "      <td>0.316120</td>\n",
       "      <td>0.094333</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.069661</td>\n",
       "      <td>0.246653</td>\n",
       "      <td>0.257355</td>\n",
       "      <td>-0.136809</td>\n",
       "      <td>0.087316</td>\n",
       "      <td>0.149096</td>\n",
       "      <td>0.196657</td>\n",
       "      <td>0.140452</td>\n",
       "      <td>-0.305898</td>\n",
       "      <td>-0.986542</td>\n",
       "      <td>-0.986421</td>\n",
       "      <td>-0.986431</td>\n",
       "      <td>-0.986496</td>\n",
       "      <td>-0.997045</td>\n",
       "      <td>-0.986542</td>\n",
       "      <td>-0.999737</td>\n",
       "      <td>-0.983509</td>\n",
       "      <td>-0.589006</td>\n",
       "      <td>-0.092856</td>\n",
       "      <td>0.046396</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>-0.986542</td>\n",
       "      <td>-0.986421</td>\n",
       "      <td>-0.986431</td>\n",
       "      <td>-0.986496</td>\n",
       "      <td>-0.997045</td>\n",
       "      <td>-0.986542</td>\n",
       "      <td>-0.999737</td>\n",
       "      <td>-0.983509</td>\n",
       "      <td>-0.589006</td>\n",
       "      <td>-0.092856</td>\n",
       "      <td>0.046396</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>-0.993078</td>\n",
       "      <td>-0.993381</td>\n",
       "      <td>-0.993195</td>\n",
       "      <td>-0.993402</td>\n",
       "      <td>-0.993012</td>\n",
       "      <td>-0.993078</td>\n",
       "      <td>-0.999884</td>\n",
       "      <td>-0.991736</td>\n",
       "      <td>-0.792321</td>\n",
       "      <td>0.661603</td>\n",
       "      <td>-0.247451</td>\n",
       "      <td>-0.230315</td>\n",
       "      <td>-0.436459</td>\n",
       "      <td>-0.982060</td>\n",
       "      <td>-0.987351</td>\n",
       "      <td>-0.985632</td>\n",
       "      <td>-0.990029</td>\n",
       "      <td>-0.981686</td>\n",
       "      <td>-0.982060</td>\n",
       "      <td>-0.999768</td>\n",
       "      <td>-0.983966</td>\n",
       "      <td>-0.240719</td>\n",
       "      <td>-0.201985</td>\n",
       "      <td>0.054712</td>\n",
       "      <td>0.110072</td>\n",
       "      <td>-0.079423</td>\n",
       "      <td>-0.995502</td>\n",
       "      <td>-0.995267</td>\n",
       "      <td>-0.995305</td>\n",
       "      <td>-0.995360</td>\n",
       "      <td>-0.997652</td>\n",
       "      <td>-0.995502</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.995001</td>\n",
       "      <td>-0.683016</td>\n",
       "      <td>0.595371</td>\n",
       "      <td>-0.264569</td>\n",
       "      <td>-0.315723</td>\n",
       "      <td>-0.163826</td>\n",
       "      <td>-0.995491</td>\n",
       "      <td>-0.983570</td>\n",
       "      <td>-0.991080</td>\n",
       "      <td>-0.996312</td>\n",
       "      <td>-0.983244</td>\n",
       "      <td>-0.990229</td>\n",
       "      <td>-0.994547</td>\n",
       "      <td>-0.982824</td>\n",
       "      <td>-0.989007</td>\n",
       "      <td>-0.997404</td>\n",
       "      <td>-0.987275</td>\n",
       "      <td>-0.987754</td>\n",
       "      <td>-0.994432</td>\n",
       "      <td>-0.990259</td>\n",
       "      <td>-0.996578</td>\n",
       "      <td>-0.992812</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999697</td>\n",
       "      <td>-0.999803</td>\n",
       "      <td>-0.990443</td>\n",
       "      <td>-0.991902</td>\n",
       "      <td>-0.988061</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.870398</td>\n",
       "      <td>-0.944190</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.029044</td>\n",
       "      <td>0.080302</td>\n",
       "      <td>0.185695</td>\n",
       "      <td>-0.599118</td>\n",
       "      <td>-0.908449</td>\n",
       "      <td>-0.460915</td>\n",
       "      <td>-0.813057</td>\n",
       "      <td>-0.566835</td>\n",
       "      <td>-0.771246</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999834</td>\n",
       "      <td>-0.999871</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.999964</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999825</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999912</td>\n",
       "      <td>-0.999719</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.999553</td>\n",
       "      <td>-0.999899</td>\n",
       "      <td>-0.999512</td>\n",
       "      <td>-0.999866</td>\n",
       "      <td>-0.999673</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>-0.999667</td>\n",
       "      <td>-0.999646</td>\n",
       "      <td>-0.999692</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>-0.999775</td>\n",
       "      <td>-0.999810</td>\n",
       "      <td>-0.999929</td>\n",
       "      <td>-0.999858</td>\n",
       "      <td>-0.999666</td>\n",
       "      <td>-0.999681</td>\n",
       "      <td>-0.999984</td>\n",
       "      <td>-0.999804</td>\n",
       "      <td>-0.999887</td>\n",
       "      <td>-0.999844</td>\n",
       "      <td>-0.999778</td>\n",
       "      <td>-0.999792</td>\n",
       "      <td>-0.999922</td>\n",
       "      <td>-0.994447</td>\n",
       "      <td>-0.988727</td>\n",
       "      <td>-0.991354</td>\n",
       "      <td>-0.991378</td>\n",
       "      <td>-0.986927</td>\n",
       "      <td>-0.994391</td>\n",
       "      <td>-0.989431</td>\n",
       "      <td>-0.987145</td>\n",
       "      <td>-0.993790</td>\n",
       "      <td>-0.993402</td>\n",
       "      <td>-0.987874</td>\n",
       "      <td>-0.994201</td>\n",
       "      <td>-0.997903</td>\n",
       "      <td>-0.999767</td>\n",
       "      <td>-0.965381</td>\n",
       "      <td>-0.992657</td>\n",
       "      <td>-0.999923</td>\n",
       "      <td>-0.999803</td>\n",
       "      <td>-0.999883</td>\n",
       "      <td>-0.991776</td>\n",
       "      <td>-0.990685</td>\n",
       "      <td>-0.993288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.035798</td>\n",
       "      <td>-0.093036</td>\n",
       "      <td>0.168095</td>\n",
       "      <td>-0.263851</td>\n",
       "      <td>-0.757229</td>\n",
       "      <td>-0.396039</td>\n",
       "      <td>-0.829635</td>\n",
       "      <td>-0.577038</td>\n",
       "      <td>-0.893375</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.999965</td>\n",
       "      <td>-0.999843</td>\n",
       "      <td>-0.999865</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999930</td>\n",
       "      <td>-0.999942</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.999978</td>\n",
       "      <td>-0.999827</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>-0.999927</td>\n",
       "      <td>-0.999901</td>\n",
       "      <td>-0.999895</td>\n",
       "      <td>-0.999797</td>\n",
       "      <td>-0.999888</td>\n",
       "      <td>-0.999906</td>\n",
       "      <td>-0.999681</td>\n",
       "      <td>-0.999846</td>\n",
       "      <td>-0.999693</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999798</td>\n",
       "      <td>-0.999883</td>\n",
       "      <td>-0.999722</td>\n",
       "      <td>-0.999736</td>\n",
       "      <td>-0.999806</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>-0.999885</td>\n",
       "      <td>-0.999724</td>\n",
       "      <td>-0.999841</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>-0.999869</td>\n",
       "      <td>-0.999735</td>\n",
       "      <td>-0.999204</td>\n",
       "      <td>-0.999662</td>\n",
       "      <td>-0.999756</td>\n",
       "      <td>-0.999920</td>\n",
       "      <td>-0.999828</td>\n",
       "      <td>-0.999207</td>\n",
       "      <td>-0.999824</td>\n",
       "      <td>-0.999924</td>\n",
       "      <td>-0.987110</td>\n",
       "      <td>-0.993602</td>\n",
       "      <td>-0.987191</td>\n",
       "      <td>-0.992810</td>\n",
       "      <td>-0.991646</td>\n",
       "      <td>-0.988678</td>\n",
       "      <td>-0.989671</td>\n",
       "      <td>-0.993461</td>\n",
       "      <td>-0.986526</td>\n",
       "      <td>-0.994518</td>\n",
       "      <td>-0.991801</td>\n",
       "      <td>-0.992281</td>\n",
       "      <td>-0.989701</td>\n",
       "      <td>-0.994344</td>\n",
       "      <td>-0.993144</td>\n",
       "      <td>-0.990344</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.999951</td>\n",
       "      <td>-0.999867</td>\n",
       "      <td>-0.992878</td>\n",
       "      <td>-0.996289</td>\n",
       "      <td>-0.990224</td>\n",
       "      <td>-0.723666</td>\n",
       "      <td>-0.803754</td>\n",
       "      <td>-0.817286</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.793103</td>\n",
       "      <td>0.216862</td>\n",
       "      <td>-0.135245</td>\n",
       "      <td>-0.049728</td>\n",
       "      <td>-0.572088</td>\n",
       "      <td>-0.873618</td>\n",
       "      <td>-0.135118</td>\n",
       "      <td>-0.542238</td>\n",
       "      <td>-0.379353</td>\n",
       "      <td>-0.756548</td>\n",
       "      <td>-0.999964</td>\n",
       "      <td>-0.999891</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.999973</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>-0.999903</td>\n",
       "      <td>-0.999833</td>\n",
       "      <td>-0.999893</td>\n",
       "      <td>-0.999950</td>\n",
       "      <td>-0.999948</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>-0.999860</td>\n",
       "      <td>-0.999948</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.999931</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999947</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999980</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999948</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999957</td>\n",
       "      <td>-0.999956</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.999880</td>\n",
       "      <td>-0.999879</td>\n",
       "      <td>-0.999950</td>\n",
       "      <td>-0.999875</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>-0.999910</td>\n",
       "      <td>-0.999871</td>\n",
       "      <td>-0.999952</td>\n",
       "      <td>-0.987519</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.990230</td>\n",
       "      <td>-0.998185</td>\n",
       "      <td>-0.987519</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>-0.983215</td>\n",
       "      <td>-0.907014</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.073581</td>\n",
       "      <td>-0.468422</td>\n",
       "      <td>-0.756494</td>\n",
       "      <td>-0.992769</td>\n",
       "      <td>-0.991700</td>\n",
       "      <td>-0.989055</td>\n",
       "      <td>-0.994455</td>\n",
       "      <td>-0.995562</td>\n",
       "      <td>-0.992769</td>\n",
       "      <td>-0.999895</td>\n",
       "      <td>-0.988055</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678921</td>\n",
       "      <td>-0.701131</td>\n",
       "      <td>-0.909639</td>\n",
       "      <td>-0.989413</td>\n",
       "      <td>-0.987836</td>\n",
       "      <td>-0.986850</td>\n",
       "      <td>-0.986749</td>\n",
       "      <td>-0.996199</td>\n",
       "      <td>-0.989413</td>\n",
       "      <td>-0.999876</td>\n",
       "      <td>-0.989136</td>\n",
       "      <td>-0.720891</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.035684</td>\n",
       "      <td>-0.230091</td>\n",
       "      <td>-0.511217</td>\n",
       "      <td>-0.995221</td>\n",
       "      <td>-0.995237</td>\n",
       "      <td>-0.995722</td>\n",
       "      <td>-0.995273</td>\n",
       "      <td>-0.995732</td>\n",
       "      <td>-0.995221</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.995226</td>\n",
       "      <td>-0.955696</td>\n",
       "      <td>-0.936508</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>-0.569174</td>\n",
       "      <td>-0.824705</td>\n",
       "      <td>0.849095</td>\n",
       "      <td>0.683250</td>\n",
       "      <td>0.837869</td>\n",
       "      <td>-0.992653</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>-0.999757</td>\n",
       "      <td>-0.998004</td>\n",
       "      <td>-0.981232</td>\n",
       "      <td>-0.991325</td>\n",
       "      <td>-0.786553</td>\n",
       "      <td>-0.559477</td>\n",
       "      <td>-0.761434</td>\n",
       "      <td>0.313276</td>\n",
       "      <td>-0.131208</td>\n",
       "      <td>0.191161</td>\n",
       "      <td>0.086904</td>\n",
       "      <td>0.257615</td>\n",
       "      <td>-0.272505</td>\n",
       "      <td>0.434728</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>0.439744</td>\n",
       "      <td>-0.269069</td>\n",
       "      <td>0.179414</td>\n",
       "      <td>-0.088952</td>\n",
       "      <td>-0.155804</td>\n",
       "      <td>-0.189763</td>\n",
       "      <td>0.599213</td>\n",
       "      <td>0.968224</td>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.998429</td>\n",
       "      <td>-0.988098</td>\n",
       "      <td>-0.978745</td>\n",
       "      <td>-0.998411</td>\n",
       "      <td>-0.988654</td>\n",
       "      <td>-0.978936</td>\n",
       "      <td>0.893817</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>0.912235</td>\n",
       "      <td>-0.967051</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.998318</td>\n",
       "      <td>-0.990611</td>\n",
       "      <td>-0.980412</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.616578</td>\n",
       "      <td>-0.257267</td>\n",
       "      <td>0.268918</td>\n",
       "      <td>-0.280665</td>\n",
       "      <td>0.292616</td>\n",
       "      <td>-0.166693</td>\n",
       "      <td>0.089943</td>\n",
       "      <td>-0.066327</td>\n",
       "      <td>0.067131</td>\n",
       "      <td>-0.237474</td>\n",
       "      <td>0.239268</td>\n",
       "      <td>-0.241012</td>\n",
       "      <td>0.240569</td>\n",
       "      <td>-0.408330</td>\n",
       "      <td>-0.184840</td>\n",
       "      <td>0.964797</td>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>-0.996420</td>\n",
       "      <td>-0.988359</td>\n",
       "      <td>-0.992455</td>\n",
       "      <td>-0.996597</td>\n",
       "      <td>-0.986537</td>\n",
       "      <td>-0.990686</td>\n",
       "      <td>-0.996993</td>\n",
       "      <td>-0.991818</td>\n",
       "      <td>-0.989769</td>\n",
       "      <td>0.994303</td>\n",
       "      <td>0.992544</td>\n",
       "      <td>0.985609</td>\n",
       "      <td>-0.993832</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999820</td>\n",
       "      <td>-0.999860</td>\n",
       "      <td>-0.995888</td>\n",
       "      <td>-0.986524</td>\n",
       "      <td>-0.990572</td>\n",
       "      <td>-0.850744</td>\n",
       "      <td>-0.746258</td>\n",
       "      <td>-0.796960</td>\n",
       "      <td>0.240904</td>\n",
       "      <td>0.134912</td>\n",
       "      <td>0.296903</td>\n",
       "      <td>0.287185</td>\n",
       "      <td>0.318970</td>\n",
       "      <td>-0.143364</td>\n",
       "      <td>0.477454</td>\n",
       "      <td>0.417966</td>\n",
       "      <td>0.389537</td>\n",
       "      <td>-0.030309</td>\n",
       "      <td>0.163261</td>\n",
       "      <td>0.180189</td>\n",
       "      <td>-0.272884</td>\n",
       "      <td>0.103065</td>\n",
       "      <td>0.064729</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>-0.074708</td>\n",
       "      <td>0.077392</td>\n",
       "      <td>-0.985184</td>\n",
       "      <td>-0.992378</td>\n",
       "      <td>-0.987402</td>\n",
       "      <td>-0.986944</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>-0.988163</td>\n",
       "      <td>-0.870154</td>\n",
       "      <td>-0.953360</td>\n",
       "      <td>-0.749780</td>\n",
       "      <td>0.839091</td>\n",
       "      <td>0.911184</td>\n",
       "      <td>0.821374</td>\n",
       "      <td>-0.985262</td>\n",
       "      <td>-0.999849</td>\n",
       "      <td>-0.999952</td>\n",
       "      <td>-0.999844</td>\n",
       "      <td>-0.989813</td>\n",
       "      <td>-0.993337</td>\n",
       "      <td>-0.991155</td>\n",
       "      <td>-0.628861</td>\n",
       "      <td>-0.467808</td>\n",
       "      <td>-0.650852</td>\n",
       "      <td>-0.212690</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.388099</td>\n",
       "      <td>-0.233271</td>\n",
       "      <td>-0.163221</td>\n",
       "      <td>0.186460</td>\n",
       "      <td>-0.434916</td>\n",
       "      <td>0.650137</td>\n",
       "      <td>0.239950</td>\n",
       "      <td>-0.339529</td>\n",
       "      <td>0.132537</td>\n",
       "      <td>0.473251</td>\n",
       "      <td>-0.142001</td>\n",
       "      <td>0.484419</td>\n",
       "      <td>-0.724558</td>\n",
       "      <td>-0.090770</td>\n",
       "      <td>-0.037633</td>\n",
       "      <td>-0.058289</td>\n",
       "      <td>-0.991354</td>\n",
       "      <td>-0.996473</td>\n",
       "      <td>-0.994511</td>\n",
       "      <td>-0.992882</td>\n",
       "      <td>-0.996541</td>\n",
       "      <td>-0.994383</td>\n",
       "      <td>-0.979846</td>\n",
       "      <td>-0.997509</td>\n",
       "      <td>-0.993420</td>\n",
       "      <td>0.993685</td>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>-0.995878</td>\n",
       "      <td>-0.999928</td>\n",
       "      <td>-0.999985</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.994513</td>\n",
       "      <td>-0.996718</td>\n",
       "      <td>-0.993969</td>\n",
       "      <td>-0.617738</td>\n",
       "      <td>-0.683093</td>\n",
       "      <td>-0.632927</td>\n",
       "      <td>-0.025679</td>\n",
       "      <td>-0.188139</td>\n",
       "      <td>0.230950</td>\n",
       "      <td>0.200258</td>\n",
       "      <td>-0.149400</td>\n",
       "      <td>0.271977</td>\n",
       "      <td>-0.271515</td>\n",
       "      <td>-0.009937</td>\n",
       "      <td>0.235128</td>\n",
       "      <td>-0.340967</td>\n",
       "      <td>-0.085713</td>\n",
       "      <td>0.163957</td>\n",
       "      <td>0.120590</td>\n",
       "      <td>0.107489</td>\n",
       "      <td>-0.282589</td>\n",
       "      <td>-0.992827</td>\n",
       "      <td>-0.991275</td>\n",
       "      <td>-0.991170</td>\n",
       "      <td>-0.990962</td>\n",
       "      <td>-0.997045</td>\n",
       "      <td>-0.992827</td>\n",
       "      <td>-0.999881</td>\n",
       "      <td>-0.989608</td>\n",
       "      <td>-0.704599</td>\n",
       "      <td>0.180441</td>\n",
       "      <td>-0.277657</td>\n",
       "      <td>0.515562</td>\n",
       "      <td>-0.355851</td>\n",
       "      <td>-0.992827</td>\n",
       "      <td>-0.991275</td>\n",
       "      <td>-0.991170</td>\n",
       "      <td>-0.990962</td>\n",
       "      <td>-0.997045</td>\n",
       "      <td>-0.992827</td>\n",
       "      <td>-0.999881</td>\n",
       "      <td>-0.989608</td>\n",
       "      <td>-0.704599</td>\n",
       "      <td>0.180441</td>\n",
       "      <td>-0.277657</td>\n",
       "      <td>0.515562</td>\n",
       "      <td>-0.355851</td>\n",
       "      <td>-0.993480</td>\n",
       "      <td>-0.995854</td>\n",
       "      <td>-0.996107</td>\n",
       "      <td>-0.993283</td>\n",
       "      <td>-0.981325</td>\n",
       "      <td>-0.993480</td>\n",
       "      <td>-0.999902</td>\n",
       "      <td>-0.996846</td>\n",
       "      <td>-0.850026</td>\n",
       "      <td>0.311604</td>\n",
       "      <td>-0.170121</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>-0.458299</td>\n",
       "      <td>-0.985204</td>\n",
       "      <td>-0.989063</td>\n",
       "      <td>-0.989613</td>\n",
       "      <td>-0.987029</td>\n",
       "      <td>-0.981686</td>\n",
       "      <td>-0.985204</td>\n",
       "      <td>-0.999829</td>\n",
       "      <td>-0.992338</td>\n",
       "      <td>-0.338699</td>\n",
       "      <td>-0.236993</td>\n",
       "      <td>0.093820</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.039039</td>\n",
       "      <td>-0.995808</td>\n",
       "      <td>-0.995258</td>\n",
       "      <td>-0.996307</td>\n",
       "      <td>-0.992389</td>\n",
       "      <td>-0.992193</td>\n",
       "      <td>-0.995808</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.996484</td>\n",
       "      <td>-0.720171</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>-0.260562</td>\n",
       "      <td>-0.145665</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.997286</td>\n",
       "      <td>-0.982301</td>\n",
       "      <td>-0.988369</td>\n",
       "      <td>-0.998606</td>\n",
       "      <td>-0.980129</td>\n",
       "      <td>-0.991915</td>\n",
       "      <td>-0.997725</td>\n",
       "      <td>-0.982353</td>\n",
       "      <td>-0.990915</td>\n",
       "      <td>-0.999277</td>\n",
       "      <td>-0.980848</td>\n",
       "      <td>-0.989116</td>\n",
       "      <td>-0.994968</td>\n",
       "      <td>-0.991788</td>\n",
       "      <td>-0.974494</td>\n",
       "      <td>-0.992423</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999625</td>\n",
       "      <td>-0.999798</td>\n",
       "      <td>-0.993760</td>\n",
       "      <td>-0.988180</td>\n",
       "      <td>-0.986359</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.870398</td>\n",
       "      <td>-0.944190</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.181090</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.559786</td>\n",
       "      <td>-0.676997</td>\n",
       "      <td>-0.951371</td>\n",
       "      <td>-0.180383</td>\n",
       "      <td>-0.533726</td>\n",
       "      <td>-0.585517</td>\n",
       "      <td>-0.790433</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>-0.999945</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999956</td>\n",
       "      <td>-0.999564</td>\n",
       "      <td>-0.999860</td>\n",
       "      <td>-0.999863</td>\n",
       "      <td>-0.999898</td>\n",
       "      <td>-0.999650</td>\n",
       "      <td>-0.999712</td>\n",
       "      <td>-0.999516</td>\n",
       "      <td>-0.999911</td>\n",
       "      <td>-0.999610</td>\n",
       "      <td>-0.999845</td>\n",
       "      <td>-0.999667</td>\n",
       "      <td>-0.999667</td>\n",
       "      <td>-0.999621</td>\n",
       "      <td>-0.999842</td>\n",
       "      <td>-0.999806</td>\n",
       "      <td>-0.999834</td>\n",
       "      <td>-0.999825</td>\n",
       "      <td>-0.999786</td>\n",
       "      <td>-0.999745</td>\n",
       "      <td>-0.999656</td>\n",
       "      <td>-0.999026</td>\n",
       "      <td>-0.999436</td>\n",
       "      <td>-0.999823</td>\n",
       "      <td>-0.999844</td>\n",
       "      <td>-0.999750</td>\n",
       "      <td>-0.999150</td>\n",
       "      <td>-0.999812</td>\n",
       "      <td>-0.999793</td>\n",
       "      <td>-0.996292</td>\n",
       "      <td>-0.988790</td>\n",
       "      <td>-0.990624</td>\n",
       "      <td>-0.996903</td>\n",
       "      <td>-0.988607</td>\n",
       "      <td>-0.992907</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.988867</td>\n",
       "      <td>-0.991673</td>\n",
       "      <td>-0.997009</td>\n",
       "      <td>-0.990373</td>\n",
       "      <td>-0.995142</td>\n",
       "      <td>-0.995796</td>\n",
       "      <td>-0.996113</td>\n",
       "      <td>-0.995979</td>\n",
       "      <td>-0.993259</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999821</td>\n",
       "      <td>-0.999860</td>\n",
       "      <td>-0.996141</td>\n",
       "      <td>-0.992408</td>\n",
       "      <td>-0.986179</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.273350</td>\n",
       "      <td>0.079135</td>\n",
       "      <td>0.292384</td>\n",
       "      <td>-0.522157</td>\n",
       "      <td>-0.812987</td>\n",
       "      <td>-0.496560</td>\n",
       "      <td>-0.903908</td>\n",
       "      <td>-0.764369</td>\n",
       "      <td>-0.966204</td>\n",
       "      <td>-0.999995</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999947</td>\n",
       "      <td>-0.999939</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.999929</td>\n",
       "      <td>-0.999958</td>\n",
       "      <td>-0.999995</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999941</td>\n",
       "      <td>-0.999959</td>\n",
       "      <td>-0.999958</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999939</td>\n",
       "      <td>-0.999925</td>\n",
       "      <td>-0.999877</td>\n",
       "      <td>-0.999810</td>\n",
       "      <td>-0.999932</td>\n",
       "      <td>-0.999728</td>\n",
       "      <td>-0.999769</td>\n",
       "      <td>-0.999503</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999878</td>\n",
       "      <td>-0.999839</td>\n",
       "      <td>-0.999728</td>\n",
       "      <td>-0.999568</td>\n",
       "      <td>-0.999830</td>\n",
       "      <td>-0.999874</td>\n",
       "      <td>-0.999845</td>\n",
       "      <td>-0.999853</td>\n",
       "      <td>-0.999890</td>\n",
       "      <td>-0.999818</td>\n",
       "      <td>-0.999760</td>\n",
       "      <td>-0.999688</td>\n",
       "      <td>-0.999169</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-0.999853</td>\n",
       "      <td>-0.999884</td>\n",
       "      <td>-0.999730</td>\n",
       "      <td>-0.999211</td>\n",
       "      <td>-0.999900</td>\n",
       "      <td>-0.999809</td>\n",
       "      <td>-0.982446</td>\n",
       "      <td>-0.992984</td>\n",
       "      <td>-0.988666</td>\n",
       "      <td>-0.985982</td>\n",
       "      <td>-0.991956</td>\n",
       "      <td>-0.987944</td>\n",
       "      <td>-0.982581</td>\n",
       "      <td>-0.993343</td>\n",
       "      <td>-0.986461</td>\n",
       "      <td>-0.987950</td>\n",
       "      <td>-0.993228</td>\n",
       "      <td>-0.991444</td>\n",
       "      <td>-0.993738</td>\n",
       "      <td>-0.993725</td>\n",
       "      <td>-0.994835</td>\n",
       "      <td>-0.988706</td>\n",
       "      <td>-0.999862</td>\n",
       "      <td>-0.999951</td>\n",
       "      <td>-0.999864</td>\n",
       "      <td>-0.990464</td>\n",
       "      <td>-0.996123</td>\n",
       "      <td>-0.997426</td>\n",
       "      <td>-0.652617</td>\n",
       "      <td>-0.827212</td>\n",
       "      <td>-0.737458</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.806452</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.153343</td>\n",
       "      <td>-0.088403</td>\n",
       "      <td>-0.162230</td>\n",
       "      <td>-0.339597</td>\n",
       "      <td>-0.722628</td>\n",
       "      <td>-0.265471</td>\n",
       "      <td>-0.689988</td>\n",
       "      <td>-0.267996</td>\n",
       "      <td>-0.659208</td>\n",
       "      <td>-0.999870</td>\n",
       "      <td>-0.999912</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>-0.999941</td>\n",
       "      <td>-0.999936</td>\n",
       "      <td>-0.999887</td>\n",
       "      <td>-0.999900</td>\n",
       "      <td>-0.999917</td>\n",
       "      <td>-0.999865</td>\n",
       "      <td>-0.999918</td>\n",
       "      <td>-0.999911</td>\n",
       "      <td>-0.999908</td>\n",
       "      <td>-0.999864</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.999967</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.999949</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-0.999871</td>\n",
       "      <td>-0.999955</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.999907</td>\n",
       "      <td>-0.999921</td>\n",
       "      <td>-0.999981</td>\n",
       "      <td>-0.999864</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999937</td>\n",
       "      <td>-0.999947</td>\n",
       "      <td>-0.999866</td>\n",
       "      <td>-0.999973</td>\n",
       "      <td>-0.993591</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.990506</td>\n",
       "      <td>-0.987805</td>\n",
       "      <td>-0.993591</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>-0.997343</td>\n",
       "      <td>-0.907014</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.394310</td>\n",
       "      <td>-0.112663</td>\n",
       "      <td>-0.481805</td>\n",
       "      <td>-0.995523</td>\n",
       "      <td>-0.994389</td>\n",
       "      <td>-0.993305</td>\n",
       "      <td>-0.995485</td>\n",
       "      <td>-0.982177</td>\n",
       "      <td>-0.995523</td>\n",
       "      <td>-0.999941</td>\n",
       "      <td>-0.994169</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.559058</td>\n",
       "      <td>-0.528901</td>\n",
       "      <td>-0.858933</td>\n",
       "      <td>-0.991433</td>\n",
       "      <td>-0.989059</td>\n",
       "      <td>-0.987744</td>\n",
       "      <td>-0.991462</td>\n",
       "      <td>-0.998353</td>\n",
       "      <td>-0.991433</td>\n",
       "      <td>-0.999902</td>\n",
       "      <td>-0.989321</td>\n",
       "      <td>-0.763372</td>\n",
       "      <td>-0.897436</td>\n",
       "      <td>-0.273582</td>\n",
       "      <td>-0.510282</td>\n",
       "      <td>-0.830702</td>\n",
       "      <td>-0.995093</td>\n",
       "      <td>-0.995465</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.995609</td>\n",
       "      <td>-0.997418</td>\n",
       "      <td>-0.995093</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.995487</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.936508</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n",
       "1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n",
       "2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n",
       "3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n",
       "4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n",
       "\n",
       "        7         8         9         10        11        12        13   \\\n",
       "0 -0.983185 -0.923527 -0.934724 -0.567378 -0.744413  0.852947  0.685845   \n",
       "1 -0.974914 -0.957686 -0.943068 -0.557851 -0.818409  0.849308  0.685845   \n",
       "2 -0.963668 -0.977469 -0.938692 -0.557851 -0.818409  0.843609  0.682401   \n",
       "3 -0.982750 -0.989302 -0.938692 -0.576159 -0.829711  0.843609  0.682401   \n",
       "4 -0.979672 -0.990441 -0.942469 -0.569174 -0.824705  0.849095  0.683250   \n",
       "\n",
       "        14        15        16        17        18        19        20   \\\n",
       "0  0.814263 -0.965523 -0.999945 -0.999863 -0.994612 -0.994231 -0.987614   \n",
       "1  0.822637 -0.981930 -0.999991 -0.999788 -0.998405 -0.999150 -0.977866   \n",
       "2  0.839344 -0.983478 -0.999969 -0.999660 -0.999470 -0.997130 -0.964810   \n",
       "3  0.837869 -0.986093 -0.999976 -0.999736 -0.999504 -0.997180 -0.983799   \n",
       "4  0.837869 -0.992653 -0.999991 -0.999856 -0.999757 -0.998004 -0.981232   \n",
       "\n",
       "        21        22        23        24        25        26        27   \\\n",
       "0 -0.943220 -0.407747 -0.679338 -0.602122  0.929294 -0.853011  0.359910   \n",
       "1 -0.948225 -0.714892 -0.500930 -0.570979  0.611627 -0.329549  0.284213   \n",
       "2 -0.974675 -0.592235 -0.485821 -0.570979  0.273025 -0.086309  0.337202   \n",
       "3 -0.986007 -0.627446 -0.850930 -0.911872  0.061436  0.074840  0.198204   \n",
       "4 -0.991325 -0.786553 -0.559477 -0.761434  0.313276 -0.131208  0.191161   \n",
       "\n",
       "        28        29        30        31        32        33        34   \\\n",
       "0 -0.058526  0.256892 -0.224848  0.264106 -0.095246  0.278851 -0.465085   \n",
       "1  0.284595  0.115705 -0.090963  0.294310 -0.281211  0.085988 -0.022153   \n",
       "2 -0.164739  0.017150 -0.074507  0.342256 -0.332564  0.239281 -0.136204   \n",
       "3 -0.264307  0.072545 -0.155320  0.323154 -0.170813  0.294938 -0.306081   \n",
       "4  0.086904  0.257615 -0.272505  0.434728 -0.315375  0.439744 -0.269069   \n",
       "\n",
       "        35        36        37        38        39        40        41   \\\n",
       "0  0.491936 -0.190884  0.376314  0.435129  0.660790  0.963396 -0.140840   \n",
       "1 -0.016657 -0.220643 -0.013429 -0.072692  0.579382  0.966561 -0.141551   \n",
       "2  0.173863 -0.299493 -0.124698 -0.181105  0.608900  0.966878 -0.142010   \n",
       "3  0.482148 -0.470129 -0.305693 -0.362654  0.507459  0.967615 -0.143976   \n",
       "4  0.179414 -0.088952 -0.155804 -0.189763  0.599213  0.968224 -0.148750   \n",
       "\n",
       "        42        43        44        45        46        47        48   \\\n",
       "0  0.115375 -0.985250 -0.981708 -0.877625 -0.985001 -0.984416 -0.894677   \n",
       "1  0.109379 -0.997411 -0.989447 -0.931639 -0.997884 -0.989614 -0.933240   \n",
       "2  0.101884 -0.999574 -0.992866 -0.992917 -0.999635 -0.992605 -0.992934   \n",
       "3  0.099850 -0.996646 -0.981393 -0.978476 -0.996457 -0.980962 -0.978456   \n",
       "4  0.094486 -0.998429 -0.988098 -0.978745 -0.998411 -0.988654 -0.978936   \n",
       "\n",
       "        49        50        51        52        53        54        55   \\\n",
       "0  0.892055 -0.161265  0.124660  0.977436 -0.123213  0.056483 -0.375426   \n",
       "1  0.892060 -0.161343  0.122586  0.984520 -0.114893  0.102764 -0.383430   \n",
       "2  0.892401 -0.163711  0.094566  0.986770 -0.114893  0.102764 -0.401602   \n",
       "3  0.893817 -0.163711  0.093425  0.986821 -0.121336  0.095753 -0.400278   \n",
       "4  0.893817 -0.166786  0.091682  0.987434 -0.121834  0.094059 -0.400477   \n",
       "\n",
       "        56        57        58        59        60        61   62   63   \\\n",
       "0  0.899469 -0.970905 -0.975510 -0.984325 -0.988849 -0.917743 -1.0 -1.0   \n",
       "1  0.907829 -0.970583 -0.978500 -0.999188 -0.990029 -0.941685 -1.0 -1.0   \n",
       "2  0.908668 -0.970368 -0.981672 -0.999679 -0.992104 -0.992619 -1.0 -1.0   \n",
       "3  0.910621 -0.969400 -0.982420 -0.995976 -0.980663 -0.979779 -1.0 -1.0   \n",
       "4  0.912235 -0.967051 -0.984363 -0.998318 -0.990611 -0.980412 -1.0 -1.0   \n",
       "\n",
       "        64        65        66        67        68        69        70   \\\n",
       "0  0.113806 -0.590425  0.591146 -0.591773  0.592469 -0.745449  0.720862   \n",
       "1 -0.210494 -0.410056  0.413856 -0.417567  0.421325 -0.196359  0.125345   \n",
       "2 -0.926776  0.002234  0.027481 -0.056728  0.085533 -0.329023  0.270500   \n",
       "3 -0.596101 -0.064935  0.075427 -0.085823  0.096208 -0.295036  0.228310   \n",
       "4 -0.616578 -0.257267  0.268918 -0.280665  0.292616 -0.166693  0.089943   \n",
       "\n",
       "        71        72        73        74        75        76        77   \\\n",
       "0 -0.712372  0.711300 -0.995112  0.995675 -0.995668  0.991653  0.570222   \n",
       "1 -0.105568  0.109090 -0.833882  0.834271 -0.834184  0.830464 -0.831284   \n",
       "2 -0.254490  0.257598 -0.705039  0.714392 -0.723299  0.728755 -0.181090   \n",
       "3 -0.206281  0.204801 -0.385410  0.386373 -0.387120  0.385263 -0.991309   \n",
       "4 -0.066327  0.067131 -0.237474  0.239268 -0.241012  0.240569 -0.408330   \n",
       "\n",
       "        78        79        80        81        82        83        84   \\\n",
       "0  0.439027  0.986913  0.077996  0.005001 -0.067831 -0.993519 -0.988360   \n",
       "1 -0.865711  0.974386  0.074007  0.005771  0.029377 -0.995548 -0.981064   \n",
       "2  0.337936  0.643417  0.073636  0.003104 -0.009046 -0.990743 -0.980956   \n",
       "3 -0.968821  0.984256  0.077321  0.020058 -0.009865 -0.992697 -0.987553   \n",
       "4 -0.184840  0.964797  0.073444  0.019122  0.016780 -0.996420 -0.988359   \n",
       "\n",
       "        85        86        87        88        89        90        91   \\\n",
       "0 -0.993575 -0.994488 -0.986207 -0.992818 -0.985180 -0.991994 -0.993119   \n",
       "1 -0.991846 -0.995632 -0.978938 -0.991277 -0.994545 -0.979068 -0.992257   \n",
       "2 -0.989687 -0.990933 -0.979300 -0.987238 -0.987077 -0.979068 -0.992257   \n",
       "3 -0.993498 -0.994266 -0.985717 -0.991483 -0.987077 -0.991786 -0.989769   \n",
       "4 -0.992455 -0.996597 -0.986537 -0.990686 -0.996993 -0.991818 -0.989769   \n",
       "\n",
       "        92        93        94        95        96        97        98   \\\n",
       "0  0.989835  0.991957  0.990519 -0.993522 -0.999935 -0.999820 -0.999878   \n",
       "1  0.992577  0.991808  0.988539 -0.991394 -0.999960 -0.999640 -0.999845   \n",
       "2  0.988390  0.991808  0.988539 -0.988148 -0.999894 -0.999636 -0.999795   \n",
       "3  0.988390  0.992544  0.993218 -0.992868 -0.999924 -0.999803 -0.999883   \n",
       "4  0.994303  0.992544  0.985609 -0.993832 -0.999969 -0.999820 -0.999860   \n",
       "\n",
       "        99        100       101       102       103       104       105  \\\n",
       "0 -0.994364 -0.986025 -0.989234 -0.819949 -0.793046 -0.888853  1.000000   \n",
       "1 -0.993863 -0.979435 -0.993384 -0.875096 -0.655362 -0.767381  0.489662   \n",
       "2 -0.987846 -0.980145 -0.981911 -0.753629 -0.673274 -0.747107  0.265225   \n",
       "3 -0.994678 -0.987033 -0.988896 -0.820804 -0.754968 -0.825279  0.122893   \n",
       "4 -0.995888 -0.986524 -0.990572 -0.850744 -0.746258 -0.796960  0.240904   \n",
       "\n",
       "        106       107       108       109       110       111       112  \\\n",
       "0 -0.220747  0.636831  0.387644  0.241401 -0.052253  0.264177  0.373439   \n",
       "1  0.070997  0.362714  0.527303  0.149396  0.062925  0.370493  0.413548   \n",
       "2  0.188395  0.464583  0.371718  0.082665 -0.004622  0.327470  0.437623   \n",
       "3  0.276419  0.457445  0.193414  0.102405 -0.099103  0.194679  0.484244   \n",
       "4  0.134912  0.296903  0.287185  0.318970 -0.143364  0.477454  0.417966   \n",
       "\n",
       "        113       114       115       116       117       118       119  \\\n",
       "0  0.341778 -0.569791  0.265399 -0.477875 -0.385300  0.033644 -0.126511   \n",
       "1  0.122216  0.180613  0.047424  0.166573 -0.208772  0.084104 -0.268554   \n",
       "2  0.257891  0.070030  0.186973  0.246800 -0.120105 -0.110026 -0.039953   \n",
       "3  0.357657 -0.187032  0.298069  0.451870 -0.127495 -0.083278  0.457060   \n",
       "4  0.389537 -0.030309  0.163261  0.180189 -0.272884  0.103065  0.064729   \n",
       "\n",
       "        120       121       122       123       124       125       126  \\\n",
       "0 -0.006101 -0.031365  0.107725 -0.985310 -0.976623 -0.992205 -0.984586   \n",
       "1 -0.016112 -0.083894  0.100584 -0.983120 -0.989046 -0.989121 -0.986890   \n",
       "2 -0.031698 -0.102335  0.096127 -0.976292 -0.993552 -0.986379 -0.974922   \n",
       "3 -0.043410 -0.091386  0.085538 -0.991385 -0.992407 -0.987554 -0.991589   \n",
       "4 -0.033960 -0.074708  0.077392 -0.985184 -0.992378 -0.987402 -0.986944   \n",
       "\n",
       "        127       128       129       130       131       132       133  \\\n",
       "0 -0.976353 -0.992362 -0.867044 -0.933786 -0.747566  0.847308  0.914895   \n",
       "1 -0.989038 -0.989185 -0.864904 -0.953560 -0.745870  0.833721  0.908110   \n",
       "2 -0.994122 -0.985786 -0.864904 -0.959049 -0.743277  0.833721  0.905753   \n",
       "3 -0.993142 -0.989585 -0.885320 -0.956656 -0.743277  0.834164  0.905753   \n",
       "4 -0.992542 -0.988163 -0.870154 -0.953360 -0.749780  0.839091  0.911184   \n",
       "\n",
       "        134       135       136       137       138       139       140  \\\n",
       "0  0.830841 -0.967184 -0.999578 -0.999354 -0.999763 -0.983438 -0.978614   \n",
       "1  0.828935 -0.980613 -0.999756 -0.999897 -0.999822 -0.992833 -0.989345   \n",
       "2  0.828935 -0.976280 -0.999693 -0.999828 -0.999822 -0.972354 -0.995144   \n",
       "3  0.826634 -0.982296 -0.999793 -0.999902 -0.999877 -0.991031 -0.994165   \n",
       "4  0.821374 -0.985262 -0.999849 -0.999952 -0.999844 -0.989813 -0.993337   \n",
       "\n",
       "        141       142       143       144       145       146       147  \\\n",
       "0 -0.992966  0.082632  0.202268 -0.168757  0.096323 -0.274985  0.498644   \n",
       "1 -0.990240  0.007469 -0.531157 -0.177445 -0.387681  0.179138  0.210789   \n",
       "2 -0.986831 -0.260943 -1.000000 -0.248371 -0.437156  0.238981  0.145238   \n",
       "3 -0.994582 -0.930551 -0.826618 -0.543422 -0.165885 -0.012881  0.320055   \n",
       "4 -0.991155 -0.628861 -0.467808 -0.650852 -0.212690  0.002111  0.388099   \n",
       "\n",
       "        148       149       150       151       152       153       154  \\\n",
       "0 -0.220317  1.000000 -0.972971  0.316655  0.375726  0.723399 -0.771112   \n",
       "1 -0.140260 -0.047032 -0.064949  0.117687  0.081691  0.042364 -0.149928   \n",
       "2 -0.113917  0.032312 -0.127879  0.114924  0.125398  0.112092 -0.165645   \n",
       "3 -0.165114  0.044553 -0.125193  0.078321  0.177028  0.193402 -0.207189   \n",
       "4 -0.233271 -0.163221  0.186460 -0.434916  0.650137  0.239950 -0.339529   \n",
       "\n",
       "        155       156       157       158       159       160       161  \\\n",
       "0  0.690213 -0.331831  0.709584  0.134873  0.301099 -0.099167 -0.055517   \n",
       "1  0.292619 -0.149429  0.046721 -0.256929  0.169395 -0.110503 -0.044819   \n",
       "2  0.134554  0.184349 -0.010130  0.043312 -0.350646 -0.108486 -0.042410   \n",
       "3  0.112457  0.202092  0.210194  0.141101 -0.725301 -0.091170 -0.036333   \n",
       "4  0.132537  0.473251 -0.142001  0.484419 -0.724558 -0.090770 -0.037633   \n",
       "\n",
       "        162       163       164       165       166       167       168  \\\n",
       "0 -0.061986 -0.992111 -0.992519 -0.992055 -0.992165 -0.994942 -0.992619   \n",
       "1 -0.059243 -0.989873 -0.997293 -0.993851 -0.989876 -0.997492 -0.993778   \n",
       "2 -0.055829 -0.988462 -0.995632 -0.991532 -0.987868 -0.995725 -0.991596   \n",
       "3 -0.060465 -0.991119 -0.996641 -0.993329 -0.991241 -0.996958 -0.994019   \n",
       "4 -0.058289 -0.991354 -0.996473 -0.994511 -0.992882 -0.996541 -0.994383   \n",
       "\n",
       "        169       170       171       172       173       174       175  \\\n",
       "0 -0.990156 -0.986743 -0.992042  0.994429  0.991756  0.989352 -0.994453   \n",
       "1 -0.991947 -0.997717 -0.994921  0.990486  0.997122  0.994503 -0.995298   \n",
       "2 -0.993359 -0.993800 -0.988963  0.989290  0.997122  0.994143 -0.993415   \n",
       "3 -0.993676 -0.993800 -0.988963  0.989290  0.998130  0.994143 -0.995496   \n",
       "4 -0.979846 -0.997509 -0.993420  0.993685  0.997453  0.996528 -0.995878   \n",
       "\n",
       "        176       177       178       179       180       181       182  \\\n",
       "0 -0.999938 -0.999954 -0.999923 -0.992300 -0.996939 -0.992243 -0.589851   \n",
       "1 -0.999908 -0.999990 -0.999946 -0.990742 -0.997301 -0.993808 -0.600945   \n",
       "2 -0.999887 -0.999980 -0.999916 -0.987130 -0.995428 -0.992776 -0.543635   \n",
       "3 -0.999925 -0.999986 -0.999940 -0.990909 -0.997078 -0.995405 -0.562031   \n",
       "4 -0.999928 -0.999985 -0.999954 -0.994513 -0.996718 -0.993969 -0.617738   \n",
       "\n",
       "        183       184       185       186       187       188       189  \\\n",
       "0 -0.688459 -0.572107  0.292376 -0.361998  0.405543 -0.039007  0.989284   \n",
       "1 -0.748247 -0.608932 -0.193308 -0.067406  0.185619  0.041522  0.072353   \n",
       "2 -0.672957 -0.588410 -0.241151 -0.011377  0.116134  0.089630  0.095986   \n",
       "3 -0.731332 -0.661434  0.009895 -0.137571  0.125965  0.316120  0.094333   \n",
       "4 -0.683093 -0.632927 -0.025679 -0.188139  0.230950  0.200258 -0.149400   \n",
       "\n",
       "        190       191       192       193       194       195       196  \\\n",
       "0 -0.414560  0.391603  0.282251  0.927270 -0.572370  0.691619  0.468290   \n",
       "1 -0.035378  0.177606  0.027498  0.182703 -0.167457  0.253251  0.132334   \n",
       "2  0.009604  0.095126  0.252887  0.181649 -0.169308  0.132009  0.008197   \n",
       "3  0.026171  0.069661  0.246653  0.257355 -0.136809  0.087316  0.149096   \n",
       "4  0.271977 -0.271515 -0.009937  0.235128 -0.340967 -0.085713  0.163957   \n",
       "\n",
       "        197       198       199       200       201       202       203  \\\n",
       "0 -0.131077 -0.087160  0.336247 -0.959434 -0.950551 -0.957993 -0.946305   \n",
       "1  0.293855 -0.018075 -0.343337 -0.979289 -0.976057 -0.978247 -0.978711   \n",
       "2  0.193329  0.073718 -0.314858 -0.983703 -0.988020 -0.988327 -0.986496   \n",
       "3  0.196657  0.140452 -0.305898 -0.986542 -0.986421 -0.986431 -0.986496   \n",
       "4  0.120590  0.107489 -0.282589 -0.992827 -0.991275 -0.991170 -0.990962   \n",
       "\n",
       "        204       205       206       207       208       209       210  \\\n",
       "0 -0.992556 -0.959434 -0.998493 -0.957637 -0.232582 -0.173179 -0.022897   \n",
       "1 -0.995333 -0.979289 -0.999488 -0.981248 -0.441876  0.081569 -0.109366   \n",
       "2 -0.995333 -0.983703 -0.999682 -0.985767 -0.599939  0.038049 -0.074212   \n",
       "3 -0.997045 -0.986542 -0.999737 -0.983509 -0.589006 -0.092856  0.046396   \n",
       "4 -0.997045 -0.992827 -0.999881 -0.989608 -0.704599  0.180441 -0.277657   \n",
       "\n",
       "        211       212       213       214       215       216       217  \\\n",
       "0  0.094832  0.191817 -0.959434 -0.950551 -0.957993 -0.946305 -0.992556   \n",
       "1  0.311758 -0.411675 -0.979289 -0.976057 -0.978247 -0.978711 -0.995333   \n",
       "2  0.254076 -0.296130 -0.983703 -0.988020 -0.988327 -0.986496 -0.995333   \n",
       "3 -0.000466  0.037143 -0.986542 -0.986421 -0.986431 -0.986496 -0.997045   \n",
       "4  0.515562 -0.355851 -0.992827 -0.991275 -0.991170 -0.990962 -0.997045   \n",
       "\n",
       "        218       219       220       221       222       223       224  \\\n",
       "0 -0.959434 -0.998493 -0.957637 -0.232582 -0.173179 -0.022897  0.094832   \n",
       "1 -0.979289 -0.999488 -0.981248 -0.441876  0.081569 -0.109366  0.311758   \n",
       "2 -0.983703 -0.999682 -0.985767 -0.599939  0.038049 -0.074212  0.254076   \n",
       "3 -0.986542 -0.999737 -0.983509 -0.589006 -0.092856  0.046396 -0.000466   \n",
       "4 -0.992827 -0.999881 -0.989608 -0.704599  0.180441 -0.277657  0.515562   \n",
       "\n",
       "        225       226       227       228       229       230       231  \\\n",
       "0  0.191817 -0.993306 -0.994336 -0.994500 -0.992784 -0.991208 -0.993306   \n",
       "1 -0.411675 -0.991253 -0.991694 -0.992716 -0.988661 -0.991208 -0.991253   \n",
       "2 -0.296130 -0.988531 -0.990397 -0.990650 -0.988661 -0.993012 -0.988531   \n",
       "3  0.037143 -0.993078 -0.993381 -0.993195 -0.993402 -0.993012 -0.993078   \n",
       "4 -0.355851 -0.993480 -0.995854 -0.996107 -0.993283 -0.981325 -0.993480   \n",
       "\n",
       "        232       233       234       235       236       237       238  \\\n",
       "0 -0.999892 -0.992934 -0.863415  0.283085 -0.237309 -0.105432 -0.038212   \n",
       "1 -0.999845 -0.993485 -0.819928  0.458812 -0.244941  0.056139 -0.458346   \n",
       "2 -0.999790 -0.989984 -0.794884  0.649704 -0.260088 -0.128416 -0.520541   \n",
       "3 -0.999884 -0.991736 -0.792321  0.661603 -0.247451 -0.230315 -0.436459   \n",
       "4 -0.999902 -0.996846 -0.850026  0.311604 -0.170121  0.134370 -0.458299   \n",
       "\n",
       "        239       240       241       242       243       244       245  \\\n",
       "0 -0.968959 -0.964335 -0.957245 -0.975060 -0.991554 -0.968959 -0.999286   \n",
       "1 -0.980683 -0.983754 -0.982003 -0.984715 -0.991554 -0.980683 -0.999725   \n",
       "2 -0.976317 -0.986051 -0.984458 -0.984715 -0.966193 -0.976317 -0.999641   \n",
       "3 -0.982060 -0.987351 -0.985632 -0.990029 -0.981686 -0.982060 -0.999768   \n",
       "4 -0.985204 -0.989063 -0.989613 -0.987029 -0.981686 -0.985204 -0.999829   \n",
       "\n",
       "        246       247       248       249       250       251       252  \\\n",
       "0 -0.949766  0.072579  0.572511 -0.738602  0.212578  0.433405 -0.994248   \n",
       "1 -0.982857 -0.192899 -0.225317 -0.017060  0.155777  0.082575 -0.995123   \n",
       "2 -0.983454 -0.222829 -0.226831  0.059681  0.061476  0.041702 -0.993403   \n",
       "3 -0.983966 -0.240719 -0.201985  0.054712  0.110072 -0.079423 -0.995502   \n",
       "4 -0.992338 -0.338699 -0.236993  0.093820  0.023333  0.039039 -0.995808   \n",
       "\n",
       "        253       254       255       256       257       258       259  \\\n",
       "0 -0.991368 -0.993143 -0.988936 -0.993486 -0.994248 -0.999949 -0.994547   \n",
       "1 -0.996102 -0.995839 -0.996545 -0.992006 -0.995123 -0.999970 -0.994819   \n",
       "2 -0.995091 -0.994859 -0.995360 -0.997652 -0.993403 -0.999955 -0.993988   \n",
       "3 -0.995267 -0.995305 -0.995360 -0.997652 -0.995502 -0.999970 -0.995001   \n",
       "4 -0.995258 -0.996307 -0.992389 -0.992193 -0.995808 -0.999972 -0.996484   \n",
       "\n",
       "        260       261       262       263       264       265       266  \\\n",
       "0 -0.619768  0.292840 -0.176889 -0.145779 -0.124072 -0.994783 -0.982984   \n",
       "1 -0.730722  0.209334 -0.178113 -0.103084 -0.043824 -0.997451 -0.976852   \n",
       "2 -0.662914  0.328031 -0.154560 -0.220587 -0.107514 -0.993594 -0.972511   \n",
       "3 -0.683016  0.595371 -0.264569 -0.315723 -0.163826 -0.995491 -0.983570   \n",
       "4 -0.720171  0.331858 -0.260562 -0.145665 -0.007368 -0.997286 -0.982301   \n",
       "\n",
       "        267       268       269       270       271       272       273  \\\n",
       "0 -0.939269 -0.995422 -0.983133 -0.906165 -0.996889 -0.984519 -0.932082   \n",
       "1 -0.973523 -0.998680 -0.974930 -0.955438 -0.997890 -0.976924 -0.968377   \n",
       "2 -0.983304 -0.996313 -0.965506 -0.977049 -0.994097 -0.971687 -0.982169   \n",
       "3 -0.991080 -0.996312 -0.983244 -0.990229 -0.994547 -0.982824 -0.989007   \n",
       "4 -0.988369 -0.998606 -0.980129 -0.991915 -0.997725 -0.982353 -0.990915   \n",
       "\n",
       "        274       275       276       277       278       279       280  \\\n",
       "0 -0.993756 -0.983163 -0.885054 -0.993962 -0.993446 -0.923428 -0.974733   \n",
       "1 -0.999372 -0.973770 -0.948777 -0.998281 -0.992721 -0.989514 -0.985812   \n",
       "2 -0.998158 -0.963072 -0.968596 -0.997094 -0.989924 -0.990886 -0.985821   \n",
       "3 -0.997404 -0.987275 -0.987754 -0.994432 -0.990259 -0.996578 -0.992812   \n",
       "4 -0.999277 -0.980848 -0.989116 -0.994968 -0.991788 -0.974494 -0.992423   \n",
       "\n",
       "        281       282       283       284       285       286       287  \\\n",
       "0 -0.999968 -0.999689 -0.994891 -0.995926 -0.989709 -0.987991 -0.946357   \n",
       "1 -0.999991 -0.999450 -0.998569 -0.994865 -0.980784 -0.985775 -1.000000   \n",
       "2 -0.999969 -0.999137 -0.999434 -0.988569 -0.977242 -0.981302 -1.000000   \n",
       "3 -0.999975 -0.999697 -0.999803 -0.990443 -0.991902 -0.988061 -1.000000   \n",
       "4 -0.999990 -0.999625 -0.999798 -0.993760 -0.988180 -0.986359 -1.000000   \n",
       "\n",
       "        288       289       290  291  292       293       294       295  \\\n",
       "0 -0.904748 -0.591302 -1.000000 -1.0 -1.0  0.252483  0.131836 -0.052050   \n",
       "1 -0.904748 -0.758409  0.096774 -1.0 -1.0  0.271309  0.042864 -0.014310   \n",
       "2 -0.815786 -0.813513 -0.935484 -1.0 -1.0  0.124531 -0.064611  0.082677   \n",
       "3 -0.870398 -0.944190 -1.000000 -1.0 -1.0  0.029044  0.080302  0.185695   \n",
       "4 -0.870398 -0.944190  0.096774 -1.0 -1.0  0.181090  0.057988  0.559786   \n",
       "\n",
       "        296       297       298       299       300       301       302  \\\n",
       "0  0.142051 -0.150682 -0.220547 -0.558739  0.246769 -0.007416 -0.999963   \n",
       "1 -0.692541 -0.954047 -0.049709 -0.331974  0.056675 -0.289001 -0.999996   \n",
       "2 -0.727227 -0.965419  0.163063 -0.092153 -0.044937 -0.288366 -0.999989   \n",
       "3 -0.599118 -0.908449 -0.460915 -0.813057 -0.566835 -0.771246 -0.999989   \n",
       "4 -0.676997 -0.951371 -0.180383 -0.533726 -0.585517 -0.790433 -0.999994   \n",
       "\n",
       "        303       304       305       306       307       308       309  \\\n",
       "0 -0.999987 -0.999979 -0.999962 -0.999932 -0.999725 -0.999670 -0.999986   \n",
       "1 -0.999982 -0.999944 -0.999970 -0.999919 -0.999866 -0.999965 -0.999999   \n",
       "2 -0.999962 -0.999815 -0.999847 -0.999939 -0.999922 -0.999923 -0.999997   \n",
       "3 -0.999977 -0.999834 -0.999871 -0.999992 -0.999949 -0.999964 -0.999996   \n",
       "4 -0.999986 -0.999936 -0.999945 -0.999969 -0.999935 -0.999970 -0.999986   \n",
       "\n",
       "        310       311       312       313       314       315       316  \\\n",
       "0 -0.999969 -0.999977 -0.999870 -0.999776 -0.999971 -0.999919 -0.999657   \n",
       "1 -0.999994 -0.999949 -0.999914 -0.999977 -0.999992 -0.999946 -0.999417   \n",
       "2 -0.999983 -0.999802 -0.999948 -0.999948 -0.999972 -0.999875 -0.999006   \n",
       "3 -0.999986 -0.999825 -0.999991 -0.999975 -0.999977 -0.999912 -0.999719   \n",
       "4 -0.999993 -0.999935 -0.999972 -0.999975 -0.999991 -0.999956 -0.999564   \n",
       "\n",
       "        317       318       319       320       321       322       323  \\\n",
       "0 -0.999860 -0.999867 -0.999863 -0.999738 -0.999732 -0.999493 -0.999814   \n",
       "1 -0.999813 -0.999569 -0.999874 -0.999549 -0.999737 -0.999566 -0.999905   \n",
       "2 -0.999715 -0.999658 -0.999817 -0.999636 -0.999679 -0.999616 -0.999880   \n",
       "3 -0.999750 -0.999944 -0.999940 -0.999553 -0.999899 -0.999512 -0.999866   \n",
       "4 -0.999860 -0.999863 -0.999898 -0.999650 -0.999712 -0.999516 -0.999911   \n",
       "\n",
       "        324       325       326       327       328       329       330  \\\n",
       "0 -0.999682 -0.999839 -0.999738 -0.999612 -0.999687 -0.999839 -0.993592   \n",
       "1 -0.999474 -0.999554 -0.999602 -0.999695 -0.999444 -0.999804 -0.998235   \n",
       "2 -0.999108 -0.999624 -0.999643 -0.999715 -0.999126 -0.999775 -0.999388   \n",
       "3 -0.999673 -0.999936 -0.999667 -0.999646 -0.999692 -0.999873 -0.999807   \n",
       "4 -0.999610 -0.999845 -0.999667 -0.999667 -0.999621 -0.999842 -0.999806   \n",
       "\n",
       "        331       332       333       334       335       336       337  \\\n",
       "0 -0.999476 -0.999662 -0.999642 -0.999293 -0.997892 -0.995932 -0.995146   \n",
       "1 -0.999769 -0.999692 -0.999875 -0.999666 -0.999448 -0.998930 -0.998754   \n",
       "2 -0.999725 -0.999718 -0.999798 -0.999753 -0.999629 -0.999686 -0.999912   \n",
       "3 -0.999775 -0.999810 -0.999929 -0.999858 -0.999666 -0.999681 -0.999984   \n",
       "4 -0.999834 -0.999825 -0.999786 -0.999745 -0.999656 -0.999026 -0.999436   \n",
       "\n",
       "        338       339       340       341       342       343       344  \\\n",
       "0 -0.994740 -0.999688 -0.998925 -0.995671 -0.994877 -0.999454 -0.992332   \n",
       "1 -0.998546 -0.999792 -0.999631 -0.998878 -0.998553 -0.999822 -0.995032   \n",
       "2 -0.999453 -0.999781 -0.999749 -0.999760 -0.999434 -0.999801 -0.990994   \n",
       "3 -0.999804 -0.999887 -0.999844 -0.999778 -0.999792 -0.999922 -0.994447   \n",
       "4 -0.999823 -0.999844 -0.999750 -0.999150 -0.999812 -0.999793 -0.996292   \n",
       "\n",
       "        345       346       347       348       349       350       351  \\\n",
       "0 -0.987170 -0.989696 -0.995821 -0.990936 -0.997052 -0.993805 -0.990519   \n",
       "1 -0.981311 -0.989740 -0.996652 -0.982084 -0.992627 -0.994977 -0.982929   \n",
       "2 -0.981642 -0.987566 -0.991249 -0.981415 -0.990416 -0.987751 -0.981091   \n",
       "3 -0.988727 -0.991354 -0.991378 -0.986927 -0.994391 -0.989431 -0.987145   \n",
       "4 -0.988790 -0.990624 -0.996903 -0.988607 -0.992907 -0.996091 -0.988867   \n",
       "\n",
       "        352       353       354       355       356       357       358  \\\n",
       "0 -0.996993 -0.996737 -0.991975 -0.993242 -0.998349 -0.991108 -0.959885   \n",
       "1 -0.991641 -0.997425 -0.984923 -0.993187 -0.997917 -0.982519 -0.986838   \n",
       "2 -0.987723 -0.995163 -0.985351 -0.993912 -0.997482 -0.998571 -0.997554   \n",
       "3 -0.993790 -0.993402 -0.987874 -0.994201 -0.997903 -0.999767 -0.965381   \n",
       "4 -0.991673 -0.997009 -0.990373 -0.995142 -0.995796 -0.996113 -0.995979   \n",
       "\n",
       "        359       360       361       362       363       364       365  366  \\\n",
       "0 -0.990515 -0.999935 -0.999820 -0.999884 -0.993026 -0.991373 -0.996240 -1.0   \n",
       "1 -0.989851 -0.999960 -0.999640 -0.999847 -0.992843 -0.985221 -0.991049 -1.0   \n",
       "2 -0.987237 -0.999894 -0.999637 -0.999795 -0.981817 -0.984765 -0.982364 -1.0   \n",
       "3 -0.992657 -0.999923 -0.999803 -0.999883 -0.991776 -0.990685 -0.993288 -1.0   \n",
       "4 -0.993259 -0.999969 -0.999821 -0.999860 -0.996141 -0.992408 -0.986179 -1.0   \n",
       "\n",
       "   367  368   369   370   371       372       373       374       375  \\\n",
       "0 -1.0 -1.0  1.00 -0.24 -1.00  0.870385  0.210697  0.263708 -0.703686   \n",
       "1 -1.0 -1.0 -0.32 -0.12 -0.32  0.608514 -0.053676  0.063148 -0.630305   \n",
       "2 -1.0 -1.0 -0.16 -0.48 -0.28  0.115434 -0.193436  0.038254 -0.594759   \n",
       "3 -1.0 -1.0 -0.12 -0.56 -0.28  0.035798 -0.093036  0.168095 -0.263851   \n",
       "4 -1.0 -1.0 -0.32 -0.08  0.04  0.273350  0.079135  0.292384 -0.522157   \n",
       "\n",
       "        376       377       378       379       380       381       382  \\\n",
       "0 -0.903743 -0.582574 -0.936310 -0.507345 -0.805536 -0.999986 -0.999980   \n",
       "1 -0.910394 -0.414424 -0.850586 -0.655535 -0.915987 -0.999996 -0.999980   \n",
       "2 -0.923541 -0.528934 -0.912985 -0.803407 -0.980133 -0.999994 -0.999944   \n",
       "3 -0.757229 -0.396039 -0.829635 -0.577038 -0.893375 -0.999998 -0.999965   \n",
       "4 -0.812987 -0.496560 -0.903908 -0.764369 -0.966204 -0.999995 -0.999983   \n",
       "\n",
       "        383       384       385       386       387       388       389  \\\n",
       "0 -0.999975 -0.999955 -0.999919 -0.999640 -0.999483 -0.999961 -0.999982   \n",
       "1 -0.999949 -0.999968 -0.999910 -0.999814 -0.999920 -0.999961 -0.999987   \n",
       "2 -0.999827 -0.999841 -0.999922 -0.999906 -0.999874 -0.999997 -0.999963   \n",
       "3 -0.999843 -0.999865 -0.999996 -0.999930 -0.999942 -0.999999 -0.999978   \n",
       "4 -0.999947 -0.999939 -0.999962 -0.999929 -0.999958 -0.999995 -0.999988   \n",
       "\n",
       "        390       391       392       393       394       395       396  \\\n",
       "0 -0.999971 -0.999811 -0.999485 -0.999981 -0.999852 -0.999933 -0.999900   \n",
       "1 -0.999956 -0.999877 -0.999914 -0.999974 -0.999906 -0.999861 -0.999827   \n",
       "2 -0.999804 -0.999923 -0.999875 -0.999909 -0.999843 -0.999820 -0.999744   \n",
       "3 -0.999827 -0.999982 -0.999943 -0.999927 -0.999901 -0.999895 -0.999797   \n",
       "4 -0.999941 -0.999959 -0.999958 -0.999975 -0.999939 -0.999925 -0.999877   \n",
       "\n",
       "        397       398       399       400       401       402       403  \\\n",
       "0 -0.999824 -0.999860 -0.999728 -0.999729 -0.999567 -0.999765 -0.999900   \n",
       "1 -0.999456 -0.999830 -0.999609 -0.999685 -0.999576 -0.999937 -0.999817   \n",
       "2 -0.999559 -0.999839 -0.999667 -0.999627 -0.999704 -0.999993 -0.999732   \n",
       "3 -0.999888 -0.999906 -0.999681 -0.999846 -0.999693 -1.000000 -0.999798   \n",
       "4 -0.999810 -0.999932 -0.999728 -0.999769 -0.999503 -0.999992 -0.999878   \n",
       "\n",
       "        404       405       406       407       408       409       410  \\\n",
       "0 -0.999815 -0.999710 -0.999596 -0.999852 -0.999822 -0.999400 -0.999766   \n",
       "1 -0.999532 -0.999595 -0.999626 -0.999630 -0.999759 -0.999859 -0.999846   \n",
       "2 -0.999611 -0.999618 -0.999744 -0.999613 -0.999773 -0.999871 -0.999784   \n",
       "3 -0.999883 -0.999722 -0.999736 -0.999806 -0.999856 -0.999885 -0.999724   \n",
       "4 -0.999839 -0.999728 -0.999568 -0.999830 -0.999874 -0.999845 -0.999853   \n",
       "\n",
       "        411       412       413       414       415       416       417  \\\n",
       "0 -0.999958 -0.999950 -0.999838 -0.999814 -0.998781 -0.998578 -0.999620   \n",
       "1 -0.999795 -0.999801 -0.999819 -0.999769 -0.999637 -0.999954 -0.999852   \n",
       "2 -0.999740 -0.999787 -0.999772 -0.999626 -0.999487 -0.999996 -0.999803   \n",
       "3 -0.999841 -0.999943 -0.999869 -0.999735 -0.999204 -0.999662 -0.999756   \n",
       "4 -0.999890 -0.999818 -0.999760 -0.999688 -0.999169 -0.999982 -0.999853   \n",
       "\n",
       "        418       419       420       421       422       423       424  \\\n",
       "0 -0.999984 -0.999828 -0.998681 -0.999844 -0.999928 -0.986574 -0.981762   \n",
       "1 -0.999827 -0.999800 -0.999651 -0.999835 -0.999827 -0.977387 -0.992530   \n",
       "2 -0.999792 -0.999721 -0.999514 -0.999775 -0.999787 -0.975433 -0.993715   \n",
       "3 -0.999920 -0.999828 -0.999207 -0.999824 -0.999924 -0.987110 -0.993602   \n",
       "4 -0.999884 -0.999730 -0.999211 -0.999900 -0.999809 -0.982446 -0.992984   \n",
       "\n",
       "        425       426       427       428       429       430       431  \\\n",
       "0 -0.989515 -0.985033 -0.973886 -0.994035 -0.986531 -0.983616 -0.992352   \n",
       "1 -0.989606 -0.984904 -0.987168 -0.989785 -0.979361 -0.991837 -0.987965   \n",
       "2 -0.986756 -0.976642 -0.993399 -0.987328 -0.975609 -0.993707 -0.985030   \n",
       "3 -0.987191 -0.992810 -0.991646 -0.988678 -0.989671 -0.993461 -0.986526   \n",
       "4 -0.988666 -0.985982 -0.991956 -0.987944 -0.982581 -0.993343 -0.986461   \n",
       "\n",
       "        432       433       434       435       436       437       438  \\\n",
       "0 -0.980498 -0.972271 -0.994944 -0.997569 -0.984085 -0.994335 -0.985276   \n",
       "1 -0.987354 -0.984786 -0.990151 -0.986892 -0.999054 -0.994414 -0.986869   \n",
       "2 -0.972901 -0.994986 -0.991283 -0.988312 -0.997233 -0.993636 -0.986009   \n",
       "3 -0.994518 -0.991801 -0.992281 -0.989701 -0.994344 -0.993144 -0.990344   \n",
       "4 -0.987950 -0.993228 -0.991444 -0.993738 -0.993725 -0.994835 -0.988706   \n",
       "\n",
       "        439       440       441       442       443       444       445  \\\n",
       "0 -0.999864 -0.999666 -0.999935 -0.990344 -0.994836 -0.994412 -0.712402   \n",
       "1 -0.999825 -0.999911 -0.999892 -0.987099 -0.995564 -0.987254 -0.611112   \n",
       "2 -0.999673 -0.999962 -0.999846 -0.985536 -0.995392 -0.992551 -0.590987   \n",
       "3 -0.999946 -0.999951 -0.999867 -0.992878 -0.996289 -0.990224 -0.723666   \n",
       "4 -0.999862 -0.999951 -0.999864 -0.990464 -0.996123 -0.997426 -0.652617   \n",
       "\n",
       "        446       447  448       449       450       451       452       453  \\\n",
       "0 -0.644842 -0.838993 -1.0 -1.000000 -1.000000 -0.257549  0.097947  0.547151   \n",
       "1 -0.764603 -0.751080 -1.0 -1.000000 -1.000000 -0.048167 -0.401608 -0.068178   \n",
       "2 -0.808287 -0.751080 -1.0 -0.870968 -1.000000 -0.216685 -0.017264 -0.110720   \n",
       "3 -0.803754 -0.817286 -1.0 -1.000000 -0.793103  0.216862 -0.135245 -0.049728   \n",
       "4 -0.827212 -0.737458 -1.0 -0.806452 -1.000000 -0.153343 -0.088403 -0.162230   \n",
       "\n",
       "        454       455       456       457       458       459       460  \\\n",
       "0  0.377311  0.134092  0.273372 -0.091262 -0.484347 -0.782851 -0.999865   \n",
       "1 -0.458553 -0.797014  0.387569  0.148665 -0.156909 -0.451776 -0.999851   \n",
       "2  0.090519 -0.244691 -0.429272 -0.812639 -0.391991 -0.767482 -0.999680   \n",
       "3 -0.572088 -0.873618 -0.135118 -0.542238 -0.379353 -0.756548 -0.999964   \n",
       "4 -0.339597 -0.722628 -0.265471 -0.689988 -0.267996 -0.659208 -0.999870   \n",
       "\n",
       "        461       462       463       464       465       466       467  \\\n",
       "0 -0.999932 -0.999973 -0.999970 -0.999930 -0.999959 -0.999929 -0.999985   \n",
       "1 -0.999794 -0.999913 -0.999918 -0.999896 -0.999885 -0.999784 -0.999782   \n",
       "2 -0.999828 -0.999915 -0.999932 -0.999848 -0.999842 -0.999864 -0.999862   \n",
       "3 -0.999891 -0.999946 -0.999973 -0.999877 -0.999903 -0.999833 -0.999893   \n",
       "4 -0.999912 -0.999926 -0.999941 -0.999936 -0.999887 -0.999900 -0.999917   \n",
       "\n",
       "        468       469       470       471       472       473       474  \\\n",
       "0 -0.999863 -0.999968 -0.999936 -0.999954 -0.999864 -0.999961 -0.999454   \n",
       "1 -0.999830 -0.999899 -0.999883 -0.999783 -0.999828 -0.999908 -0.999856   \n",
       "2 -0.999674 -0.999906 -0.999831 -0.999863 -0.999676 -0.999903 -0.999954   \n",
       "3 -0.999950 -0.999948 -0.999877 -0.999860 -0.999948 -0.999946 -0.999931   \n",
       "4 -0.999865 -0.999918 -0.999911 -0.999908 -0.999864 -0.999933 -0.999926   \n",
       "\n",
       "        475       476       477       478       479       480       481  \\\n",
       "0 -0.999978 -0.999992 -0.999990 -0.999969 -0.999807 -0.998346 -0.998961   \n",
       "1 -0.999988 -0.999996 -0.999994 -0.999986 -0.999985 -0.999980 -0.999990   \n",
       "2 -0.999988 -0.999990 -0.999994 -0.999973 -0.999943 -0.999987 -0.999993   \n",
       "3 -0.999989 -0.999992 -0.999993 -0.999986 -0.999954 -0.999990 -0.999988   \n",
       "4 -0.999993 -0.999996 -0.999988 -0.999967 -0.999974 -0.999974 -0.999972   \n",
       "\n",
       "        482       483       484       485       486       487       488  \\\n",
       "0 -0.999619 -0.999989 -0.999935 -0.998388 -0.999643 -0.999973 -0.999955   \n",
       "1 -0.999897 -0.999994 -0.999986 -0.999982 -0.999903 -0.999992 -0.999909   \n",
       "2 -0.999962 -0.999989 -0.999967 -0.999988 -0.999961 -0.999986 -0.999870   \n",
       "3 -0.999947 -0.999991 -0.999980 -0.999988 -0.999948 -0.999988 -0.999877   \n",
       "4 -0.999946 -0.999993 -0.999968 -0.999970 -0.999949 -0.999982 -0.999871   \n",
       "\n",
       "        489       490       491       492       493       494       495  \\\n",
       "0 -0.999976 -0.999906 -0.999985 -0.999937 -0.999751 -0.999072 -0.999928   \n",
       "1 -0.999959 -0.999928 -0.999966 -0.999985 -0.999926 -0.999961 -0.999983   \n",
       "2 -0.999935 -0.999935 -0.999957 -0.999952 -0.999909 -0.999889 -0.999989   \n",
       "3 -0.999969 -0.999957 -0.999956 -0.999949 -0.999880 -0.999879 -0.999950   \n",
       "4 -0.999955 -0.999996 -0.999986 -0.999940 -0.999907 -0.999921 -0.999981   \n",
       "\n",
       "        496       497       498       499       500       501       502  \\\n",
       "0 -0.999952 -0.999906 -0.999893 -0.999444 -0.999941 -0.999959 -0.952155   \n",
       "1 -0.999902 -0.999918 -0.999975 -0.999971 -0.999894 -0.999971 -0.980857   \n",
       "2 -0.999856 -0.999920 -0.999946 -0.999933 -0.999850 -0.999956 -0.987795   \n",
       "3 -0.999875 -0.999940 -0.999936 -0.999910 -0.999871 -0.999952 -0.987519   \n",
       "4 -0.999864 -0.999992 -0.999937 -0.999947 -0.999866 -0.999973 -0.993591   \n",
       "\n",
       "        503       504       505       506       507       508       509  \\\n",
       "0 -0.956134 -0.948870 -0.974321 -0.925722 -0.952155 -0.998285 -0.973273   \n",
       "1 -0.975866 -0.975777 -0.978226 -0.986911 -0.980857 -0.999472 -0.984479   \n",
       "2 -0.989015 -0.985594 -0.993062 -0.989836 -0.987795 -0.999807 -0.989237   \n",
       "3 -0.986742 -0.983524 -0.990230 -0.998185 -0.987519 -0.999770 -0.983215   \n",
       "4 -0.990063 -0.992324 -0.990506 -0.987805 -0.993591 -0.999873 -0.997343   \n",
       "\n",
       "        510       511       512       513       514       515       516  \\\n",
       "0 -0.646376 -0.793103 -0.088436 -0.436471 -0.796840 -0.993726 -0.993755   \n",
       "1 -0.816674 -1.000000 -0.044150 -0.122040 -0.449522 -0.990335 -0.991960   \n",
       "2 -0.907014 -0.862069  0.257899 -0.618725 -0.879685 -0.989280 -0.990867   \n",
       "3 -0.907014 -1.000000  0.073581 -0.468422 -0.756494 -0.992769 -0.991700   \n",
       "4 -0.907014 -1.000000  0.394310 -0.112663 -0.481805 -0.995523 -0.994389   \n",
       "\n",
       "        517       518       519       520       521       522  523       524  \\\n",
       "0 -0.991976 -0.993365 -0.988175 -0.993726 -0.999918 -0.991364 -1.0 -0.936508   \n",
       "1 -0.989732 -0.994489 -0.989549 -0.990335 -0.999867 -0.991134 -1.0 -0.841270   \n",
       "2 -0.987274 -0.993179 -0.999890 -0.989280 -0.999845 -0.986658 -1.0 -0.904762   \n",
       "3 -0.989055 -0.994455 -0.995562 -0.992769 -0.999895 -0.988055 -1.0  1.000000   \n",
       "4 -0.993305 -0.995485 -0.982177 -0.995523 -0.999941 -0.994169 -1.0 -1.000000   \n",
       "\n",
       "        525       526       527       528       529       530       531  \\\n",
       "0  0.346989 -0.516080 -0.802760 -0.980135 -0.961309 -0.973653 -0.952264   \n",
       "1  0.532061 -0.624871 -0.900160 -0.988296 -0.983322 -0.982659 -0.986321   \n",
       "2  0.660795 -0.724697 -0.928539 -0.989255 -0.986028 -0.984274 -0.990979   \n",
       "3  0.678921 -0.701131 -0.909639 -0.989413 -0.987836 -0.986850 -0.986749   \n",
       "4  0.559058 -0.528901 -0.858933 -0.991433 -0.989059 -0.987744 -0.991462   \n",
       "\n",
       "        532       533       534       535       536       537       538  \\\n",
       "0 -0.989498 -0.980135 -0.999240 -0.992656 -0.701291 -1.000000 -0.128989   \n",
       "1 -0.991829 -0.988296 -0.999811 -0.993979 -0.720683 -0.948718 -0.271958   \n",
       "2 -0.995703 -0.989255 -0.999854 -0.993238 -0.736521 -0.794872 -0.212728   \n",
       "3 -0.996199 -0.989413 -0.999876 -0.989136 -0.720891 -1.000000 -0.035684   \n",
       "4 -0.998353 -0.991433 -0.999902 -0.989321 -0.763372 -0.897436 -0.273582   \n",
       "\n",
       "        539       540       541       542       543       544       545  \\\n",
       "0  0.586156  0.374605 -0.991990 -0.990697 -0.989941 -0.992448 -0.991048   \n",
       "1 -0.336310 -0.720015 -0.995854 -0.996399 -0.995442 -0.996866 -0.994440   \n",
       "2 -0.535352 -0.871914 -0.995031 -0.995127 -0.994640 -0.996060 -0.995866   \n",
       "3 -0.230091 -0.511217 -0.995221 -0.995237 -0.995722 -0.995273 -0.995732   \n",
       "4 -0.510282 -0.830702 -0.995093 -0.995465 -0.995279 -0.995609 -0.997418   \n",
       "\n",
       "        546       547       548       549       550       551       552  \\\n",
       "0 -0.991990 -0.999937 -0.990458 -0.871306 -1.000000 -0.074323 -0.298676   \n",
       "1 -0.995854 -0.999981 -0.994544 -1.000000 -1.000000  0.158075 -0.595051   \n",
       "2 -0.995031 -0.999973 -0.993755 -1.000000 -0.555556  0.414503 -0.390748   \n",
       "3 -0.995221 -0.999974 -0.995226 -0.955696 -0.936508  0.404573 -0.117290   \n",
       "4 -0.995093 -0.999974 -0.995487 -1.000000 -0.936508  0.087753 -0.351471   \n",
       "\n",
       "        553       554       555       556       557       558       559  \\\n",
       "0 -0.710304 -0.112754  0.030400 -0.464761 -0.018446 -0.841247  0.179941   \n",
       "1 -0.861499  0.053477 -0.007435 -0.732626  0.703511 -0.844788  0.180289   \n",
       "2 -0.760104 -0.118559  0.177899  0.100699  0.808529 -0.848933  0.180637   \n",
       "3 -0.482845 -0.036788 -0.012892  0.640011 -0.485366 -0.848649  0.181935   \n",
       "4 -0.699205  0.123320  0.122542  0.693578 -0.615971 -0.847865  0.185151   \n",
       "\n",
       "        560  \n",
       "0 -0.058627  \n",
       "1 -0.054317  \n",
       "2 -0.049118  \n",
       "3 -0.047663  \n",
       "4 -0.043892  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "710aead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id               label\n",
      "0   1             WALKING\n",
      "1   2    WALKING_UPSTAIRS\n",
      "2   3  WALKING_DOWNSTAIRS\n",
      "3   4             SITTING\n",
      "4   5            STANDING\n",
      "5   6              LAYING\n"
     ]
    }
   ],
   "source": [
    "activity_labels_df = pd.read_csv(\"data/UCI HAR Dataset/activity_labels.txt\", sep='\\s+', header=None, names=[\"id\", \"label\"])\n",
    "print(activity_labels_df)\n",
    "labels = activity_labels_df[\"label\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6e26e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = y_train.to_numpy() - 1\n",
    "y_test_np = y_test.to_numpy() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "6c23a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d38cdc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_tensor   = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_tr_tensor   = torch.tensor(y_train.values, dtype=torch.long) - 1\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "df669ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7352, 1, 561]) torch.Size([2947, 1, 561])\n"
     ]
    }
   ],
   "source": [
    "X_tr_tensor = X_tr_tensor.view(X_tr_tensor.shape[0], 1, -1)\n",
    "X_test_tensor = X_test_tensor.view(X_test_tensor.shape[0], 1, -1)\n",
    "print(X_tr_tensor.shape, X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7c9a0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "tr_dataset   = TensorDataset(X_tr_tensor, y_tr_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader   = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True) # train \n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6ec183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_labels(y_train, y_test, fr, to):\n",
    "    return np.where(y_train == fr, to, 1), np.where(y_test == fr, to, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87355604",
   "metadata": {},
   "source": [
    "## PU-learnining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab53ff",
   "metadata": {},
   "source": [
    "### Transform Data to PU Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ebc023e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class = 2\n",
    "unlabeled_label = 0\n",
    "\n",
    "y_train = np.where(y_train_np == positive_class, 1, unlabeled_label)\n",
    "y_test = np.where(y_test_np == positive_class, 1, unlabeled_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f53cc2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives before reduction, train: 986\n",
      "Positives before reduction, test: 420\n",
      "Positives after reduction, train: 493\n",
      "Positives after reduction, test: 210\n"
     ]
    }
   ],
   "source": [
    "positive_class = 2\n",
    "unlabeled_label = 0\n",
    "\n",
    "y_train_pu = np.where(y_train_np == positive_class, 1, unlabeled_label)\n",
    "y_test_pu = np.where(y_test_np == positive_class, 1, unlabeled_label)\n",
    "print(f\"Positives before reduction, train: {y_train_pu[y_train_pu == 1].sum()}\")\n",
    "print(f\"Positives before reduction, test: {y_test_pu[y_test_pu == 1].sum()}\")\n",
    "\n",
    "\n",
    "pos_idx_tr = np.where(y_train_pu == 1)[0]\n",
    "pos_idx_tst = np.where(y_test_pu == 1)[0]\n",
    "np.random.seed(0)\n",
    "unmark_pos_tr = np.random.choice(pos_idx_tr, size=len(pos_idx_tr)//2, replace=False)\n",
    "y_train_pu[unmark_pos_tr] = unlabeled_label\n",
    "unmark_pos_tst = np.random.choice(pos_idx_tst, size=len(pos_idx_tst)//2, replace=False)\n",
    "y_test_pu[unmark_pos_tst] = unlabeled_label\n",
    "print(f\"Positives after reduction, train: {y_train_pu[y_train_pu == 1].sum()}\")\n",
    "print(f\"Positives after reduction, test: {y_test_pu[y_test_pu == 1].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "013adb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7352, 1, 561]) torch.Size([2947, 1, 561])\n"
     ]
    }
   ],
   "source": [
    "X_tr_tensor = X_tr_tensor.view(X_tr_tensor.shape[0], 1, -1)\n",
    "X_test_tensor = X_test_tensor.view(X_test_tensor.shape[0], 1, -1)\n",
    "print(X_tr_tensor.shape, X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "001c0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "55a15322",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_tensor_pu   = torch.tensor(y_train_pu, dtype=torch.long)\n",
    "y_test_tensor_pu = torch.tensor(y_test_pu, dtype=torch.long)\n",
    "\n",
    "tr_dataset_pu   = TensorDataset(X_tr_tensor, y_tr_tensor_pu)\n",
    "test_dataset_pu = TensorDataset(X_test_tensor, y_test_tensor_pu)\n",
    "\n",
    "train_loader = DataLoader(tr_dataset_pu, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset_pu, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ae46985f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0671)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive_prior = np.where(y_train_np == positive_class, 1, 0).mean()\n",
    "# positive_prior\n",
    "\n",
    "positive_prior = torch.tensor(\n",
    "    np.where(y_train_np == positive_class, 1, 0).mean(),\n",
    "    dtype=torch.float32\n",
    ")\n",
    "# positive_prior = torch.tensor((y_train_pu).mean(),\n",
    "#                               dtype=torch.float32)\n",
    "\n",
    "positive_prior = torch.tensor(\n",
    "    np.where(y_train_pu == 1, 1, 0).mean(),\n",
    "    dtype=torch.float32\n",
    ")\n",
    "positive_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80712826",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "28d0083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channel: 1, sequence_length: 561, n_output: 1\n"
     ]
    }
   ],
   "source": [
    "in_channel = X_tr_tensor.shape[1]\n",
    "seq_length = X_tr_tensor.shape[2]\n",
    "n_output = len(y_tr_tensor_pu.unique())-1\n",
    "print(f'in_channel: {in_channel}, sequence_length: {seq_length}, n_output: {n_output}')\n",
    "n_hidden = 64\n",
    "num_epochs = 15\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf519856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_Net(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=17920, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (features): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=17920, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from baseline import Conv_Net, train, LSTMNet\n",
    "model = Conv_Net(in_channel, seq_length, n_hidden, n_output=2)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_test_pu)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_test_pu)\n",
    "ce_weight = torch.tensor(weights, dtype=torch.float32, device=device)\n",
    "criterion = nn.CrossEntropyLoss(weight=ce_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427036e",
   "metadata": {},
   "source": [
    "## CrossEntropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "233cd19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 154.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], tr_loss: 0.30529 tr_acc: 0.93294 test_loss: 0.29578, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 228.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], tr_loss: 0.29184 tr_acc: 0.93294 test_loss: 0.29000, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 232.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], tr_loss: 0.28601 tr_acc: 0.93294 test_loss: 0.28508, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 246.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], tr_loss: 0.27875 tr_acc: 0.93294 test_loss: 0.28065, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 255.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], tr_loss: 0.27342 tr_acc: 0.93294 test_loss: 0.27595, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 252.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], tr_loss: 0.26923 tr_acc: 0.93294 test_loss: 0.27318, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 254.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], tr_loss: 0.26544 tr_acc: 0.93294 test_loss: 0.26963, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 253.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], tr_loss: 0.26201 tr_acc: 0.93349 test_loss: 0.26754, test_acc: 0.92942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 243.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], tr_loss: 0.25748 tr_acc: 0.93308 test_loss: 0.26403, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 250.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], tr_loss: 0.25502 tr_acc: 0.93267 test_loss: 0.26201, test_acc: 0.92467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 256.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], tr_loss: 0.25316 tr_acc: 0.93050 test_loss: 0.25936, test_acc: 0.92501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 252.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], tr_loss: 0.24922 tr_acc: 0.93199 test_loss: 0.25543, test_acc: 0.92671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 231.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], tr_loss: 0.24556 tr_acc: 0.93281 test_loss: 0.25356, test_acc: 0.92772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 229.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], tr_loss: 0.24262 tr_acc: 0.93498 test_loss: 0.25002, test_acc: 0.92806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 234.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], tr_loss: 0.24201 tr_acc: 0.93240 test_loss: 0.24990, test_acc: 0.92195\n"
     ]
    }
   ],
   "source": [
    "model = train(model, criterion, train_loader_pu, test_loader_pu, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "143cd0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9211    0.9589      6859\n",
      "           1     0.4768    1.0000    0.6457       493\n",
      "\n",
      "    accuracy                         0.9264      7352\n",
      "   macro avg     0.7384    0.9606    0.8023      7352\n",
      "weighted avg     0.9649    0.9264    0.9379      7352\n",
      "\n",
      "[[6318  541]\n",
      " [   0  493]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out_train = model(X_tr_tensor.to(device)).cpu()\n",
    "preds_train = torch.max(out_train, 1)[1]\n",
    "\n",
    "print(classification_report(y_train_pu, preds_train, digits=4))\n",
    "print(confusion_matrix(y_train_pu, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ba1b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9925    0.9962      6366\n",
      "           1     0.9536    1.0000    0.9762       986\n",
      "\n",
      "    accuracy                         0.9935      7352\n",
      "   macro avg     0.9768    0.9962    0.9862      7352\n",
      "weighted avg     0.9938    0.9935    0.9935      7352\n",
      "\n",
      "[[6318   48]\n",
      " [   0  986]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, preds_train, digits=4))\n",
    "print(confusion_matrix(y_train, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ac80e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9968    0.9189    0.9563      2737\n",
      "           1     0.4764    0.9619    0.6372       210\n",
      "\n",
      "    accuracy                         0.9220      2947\n",
      "   macro avg     0.7366    0.9404    0.7967      2947\n",
      "weighted avg     0.9597    0.9220    0.9335      2947\n",
      "\n",
      "[[2515  222]\n",
      " [   8  202]]\n"
     ]
    }
   ],
   "source": [
    "out_test = model(X_test_tensor.to(device)).cpu()\n",
    "preds_test = torch.max(out_test, 1)[1]\n",
    "\n",
    "print(classification_report(y_test_pu, preds_test, digits=4))\n",
    "print(confusion_matrix(y_test_pu, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4612382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9913    0.9897    0.9905      2527\n",
      "           1     0.9387    0.9476    0.9431       420\n",
      "\n",
      "    accuracy                         0.9837      2947\n",
      "   macro avg     0.9650    0.9687    0.9668      2947\n",
      "weighted avg     0.9838    0.9837    0.9837      2947\n",
      "\n",
      "[[2501   26]\n",
      " [  22  398]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_test, digits=4))\n",
    "print(confusion_matrix(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a309802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Total number of positive sampels:986\n",
      "Total number of unmarked positive sampels: 493\n",
      "Number of unmarked samples correctly predicted as positive: 493\n",
      "In percentage: 1.0000\n",
      "Test\n",
      "Total number of positive sampels:420\n",
      "Total number of unmarked positive sampels: 210\n",
      "Number of unmarked samples correctly predicted as positive: 196\n",
      "In percentage: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Observe the unmarked positive samples and determine in how many places the prediction matches true labels.\n",
    "print(\"Train\")\n",
    "correct_preds_num_tr = (preds_train[unmark_pos_tr] == y_train[unmark_pos_tr]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_train==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tr)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tr}\\n\\\n",
    "In percentage: {(correct_preds_num_tr/len(unmark_pos_tr)):.4f}\")\n",
    "print(\"Test\")\n",
    "correct_preds_num_tst = (preds_test[unmark_pos_tst] == y_test[unmark_pos_tst]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_test==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tst)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tst}\\n\\\n",
    "In percentage: {(correct_preds_num_tst/len(unmark_pos_tst)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8142e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/har_cnn_crossentropy.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468b9c8",
   "metadata": {},
   "source": [
    "## PU Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7dc63a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7352, 1, 561])\n"
     ]
    }
   ],
   "source": [
    "y_train_pu_tensor = torch.tensor(np.where(y_train_pu == 1, 1, -1), dtype=torch.long)\n",
    "y_test_pu_tensor = torch.tensor(np.where(y_test_pu == 1, 1, -1), dtype=torch.long)\n",
    "batch_size = 64\n",
    "print(X_tr_tensor.shape)\n",
    "train_dataset = TensorDataset(X_tr_tensor, y_train_pu_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_pu_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pu, y_test_pu = change_labels(y_train_pu, y_test_pu, 0, -1)\n",
    "y_train, y_test = change_labels(y_train, y_test, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6689a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pu_loss import PULoss\n",
    "criterion = PULoss(prior=positive_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b4550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_504/1688355383.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models/har_cnn_pu.pth\"))\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "model = Conv_Net(in_channel, seq_length, n_hidden, n_output=1)\n",
    "model.load_state_dict(torch.load(\"models/har_cnn_pu.pth\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "197f00d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bebra/aic/har-pu-learning/pu_loss.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.prior = torch.tensor(self.prior, device=inp.device)\n",
      "100%|██████████| 115/115 [00:01<00:00, 104.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], tr_loss: 0.13504 tr_acc: 0.92424 test_loss: 0.09210, test_acc: 0.92874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 132.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], tr_loss: 0.08872 tr_acc: 0.93172 test_loss: 0.08191, test_acc: 0.93146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 139.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], tr_loss: 0.07770 tr_acc: 0.93063 test_loss: 0.07921, test_acc: 0.93010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 144.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], tr_loss: 0.07385 tr_acc: 0.93131 test_loss: 0.07510, test_acc: 0.93485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 138.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], tr_loss: 0.07214 tr_acc: 0.93267 test_loss: 0.07008, test_acc: 0.93349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 131.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], tr_loss: 0.07112 tr_acc: 0.93471 test_loss: 0.06889, test_acc: 0.93247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 135.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], tr_loss: 0.06792 tr_acc: 0.93322 test_loss: 0.06739, test_acc: 0.93146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 142.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], tr_loss: 0.06507 tr_acc: 0.93607 test_loss: 0.06721, test_acc: 0.93078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 140.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], tr_loss: 0.05934 tr_acc: 0.93730 test_loss: 0.06565, test_acc: 0.93112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 177.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], tr_loss: 0.05720 tr_acc: 0.93784 test_loss: 0.06593, test_acc: 0.93180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 188.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], tr_loss: 0.05502 tr_acc: 0.94002 test_loss: 0.06563, test_acc: 0.93078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 188.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], tr_loss: 0.05346 tr_acc: 0.93702 test_loss: 0.06461, test_acc: 0.92976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 189.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], tr_loss: 0.05358 tr_acc: 0.93866 test_loss: 0.06659, test_acc: 0.93044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 172.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], tr_loss: 0.05227 tr_acc: 0.94328 test_loss: 0.06433, test_acc: 0.92942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:00<00:00, 183.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], tr_loss: 0.05167 tr_acc: 0.94029 test_loss: 0.06532, test_acc: 0.92806\n"
     ]
    }
   ],
   "source": [
    "model = train(model, criterion, train_loader, test_loader, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e4d6d779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.9938    0.9408    0.9666      6859\n",
      "           1     0.5274    0.9189    0.6701       493\n",
      "\n",
      "    accuracy                         0.9393      7352\n",
      "   macro avg     0.7606    0.9298    0.8184      7352\n",
      "weighted avg     0.9626    0.9393    0.9467      7352\n",
      "\n",
      "[[6453  406]\n",
      " [  40  453]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out_train = model(X_tr_tensor.to(device)).cpu()\n",
    "preds_train = torch.where(\n",
    "            out_train > 0,\n",
    "            torch.tensor(1, device=out_train.device),\n",
    "            torch.tensor(-1, device=out_train.device)\n",
    "        ).view(-1)\n",
    "\n",
    "print(classification_report(y_train_pu, preds_train, digits=4))\n",
    "print(confusion_matrix(y_train_pu, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b9499822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.9804    1.0000    0.9901      6366\n",
      "           1     1.0000    0.8712    0.9312       986\n",
      "\n",
      "    accuracy                         0.9827      7352\n",
      "   macro avg     0.9902    0.9356    0.9606      7352\n",
      "weighted avg     0.9831    0.9827    0.9822      7352\n",
      "\n",
      "[[6366    0]\n",
      " [ 127  859]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, preds_train, digits=4))\n",
    "print(confusion_matrix(y_train, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6b3e94f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.9766    0.9456    0.9608      2737\n",
      "           1     0.4983    0.7048    0.5838       210\n",
      "\n",
      "    accuracy                         0.9284      2947\n",
      "   macro avg     0.7375    0.8252    0.7723      2947\n",
      "weighted avg     0.9425    0.9284    0.9340      2947\n",
      "\n",
      "[[2588  149]\n",
      " [  62  148]]\n"
     ]
    }
   ],
   "source": [
    "out_test = model(X_test_tensor.to(device)).cpu()\n",
    "preds_test = torch.where(\n",
    "            out_test > 0,\n",
    "            torch.tensor(1, device=out_test.device),\n",
    "            torch.tensor(-1, device=out_test.device)\n",
    "        ).view(-1)\n",
    "\n",
    "print(classification_report(y_test_pu, preds_test.cpu().detach().numpy(), digits=4))\n",
    "print(confusion_matrix(y_test_pu, preds_test.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d4565aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.9532    0.9996    0.9759      2527\n",
      "           1     0.9966    0.7048    0.8257       420\n",
      "\n",
      "    accuracy                         0.9576      2947\n",
      "   macro avg     0.9749    0.8522    0.9008      2947\n",
      "weighted avg     0.9594    0.9576    0.9544      2947\n",
      "\n",
      "[[2526    1]\n",
      " [ 124  296]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_test.cpu().detach().numpy(), digits=4))\n",
    "print(confusion_matrix(y_test, preds_test.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "82bd0d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Total number of positive sampels:986\n",
      "Total number of unmarked positive sampels: 493\n",
      "Number of unmarked samples correctly predicted as positive: 406\n",
      "In percentage: 0.8235\n",
      "Test\n",
      "Total number of positive sampels:420\n",
      "Total number of unmarked positive sampels: 210\n",
      "Number of unmarked samples correctly predicted as positive: 148\n",
      "In percentage: 0.7048\n"
     ]
    }
   ],
   "source": [
    "# Observe the unmarked positive samples and determine in how many places the prediction matches true labels.\n",
    "print(\"Train\")\n",
    "correct_preds_num_tr = (preds_train[unmark_pos_tr] == y_train[unmark_pos_tr]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_train==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tr)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tr}\\n\\\n",
    "In percentage: {(correct_preds_num_tr/len(unmark_pos_tr)):.4f}\")\n",
    "print(\"Test\")\n",
    "correct_preds_num_tst = (preds_test[unmark_pos_tst] == y_test[unmark_pos_tst]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_test==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tst)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tst}\\n\\\n",
    "In percentage: {(correct_preds_num_tst/len(unmark_pos_tst)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "20e4348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/har_cnn_pu.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6e199",
   "metadata": {},
   "source": [
    "## Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8615052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaClassifier(\n",
      "  (input_proj): Linear(in_features=1, out_features=64, bias=True)\n",
      "  (blocks): Sequential(\n",
      "    (0): MambaBlock(\n",
      "      (mamba): Mamba(\n",
      "        (in_proj): Linear(in_features=64, out_features=256, bias=False)\n",
      "        (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
      "        (act): SiLU()\n",
      "        (x_proj): Linear(in_features=128, out_features=36, bias=False)\n",
      "        (dt_proj): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (out_proj): Linear(in_features=128, out_features=64, bias=False)\n",
      "      )\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from baseline import MambaClassifier, train, PULoss\n",
    "\n",
    "#criterion = PULoss(positive_prior=0.15, nnPU=True)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_test_pu)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_test_pu)\n",
    "ce_weight = torch.tensor(weights, dtype=torch.float32, device=device)\n",
    "criterion = nn.CrossEntropyLoss(weight=ce_weight)\n",
    "model_mamba = MambaClassifier(in_channel, hidden_dim=64, num_classes=2, num_layers=1, dropout=0.1)\n",
    "model_mamba = model_mamba.to(device)\n",
    "print(model_mamba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a8b4b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:03<00:00, 35.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], tr_loss: 0.41075 tr_acc: 0.79625 test_loss: 0.34040, test_acc: 0.80896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], tr_loss: 0.34955 tr_acc: 0.76959 test_loss: 0.34115, test_acc: 0.82457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], tr_loss: 0.34577 tr_acc: 0.76401 test_loss: 0.34406, test_acc: 0.83373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], tr_loss: 0.34607 tr_acc: 0.76224 test_loss: 0.34139, test_acc: 0.82592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], tr_loss: 0.34492 tr_acc: 0.76238 test_loss: 0.33818, test_acc: 0.81880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], tr_loss: 0.34292 tr_acc: 0.76238 test_loss: 0.33593, test_acc: 0.80964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], tr_loss: 0.34043 tr_acc: 0.76387 test_loss: 0.33479, test_acc: 0.80251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], tr_loss: 0.33827 tr_acc: 0.76387 test_loss: 0.33389, test_acc: 0.79708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], tr_loss: 0.33635 tr_acc: 0.76428 test_loss: 0.33320, test_acc: 0.79233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], tr_loss: 0.33462 tr_acc: 0.76510 test_loss: 0.33246, test_acc: 0.79063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:02<00:00, 38.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], tr_loss: 0.33310 tr_acc: 0.76659 test_loss: 0.33179, test_acc: 0.78928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:03<00:00, 38.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], tr_loss: 0.33172 tr_acc: 0.76687 test_loss: 0.33110, test_acc: 0.78724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:03<00:00, 38.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], tr_loss: 0.33041 tr_acc: 0.76877 test_loss: 0.33037, test_acc: 0.78690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:03<00:00, 37.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], tr_loss: 0.32916 tr_acc: 0.76877 test_loss: 0.32974, test_acc: 0.78453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:03<00:00, 38.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], tr_loss: 0.32766 tr_acc: 0.76931 test_loss: 0.32917, test_acc: 0.78317\n"
     ]
    }
   ],
   "source": [
    "model_mamba = train(model_mamba, criterion, train_loader, test_loader, 0.001, 15, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0d8eed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = X_test_tensor.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "47b19c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_tensor_inf = X_tr_tensor.permute(0, 2, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d82a4cd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7352, 14704]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[303], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Concatenate all predictions\u001b[39;00m\n\u001b[1;32m     18\u001b[0m preds_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(preds_train)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_pu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdigits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_train_pu, preds_train))\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2671\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m \n\u001b[1;32m   2565\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[38;5;124;03m<BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2668\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m-> 2671\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2674\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7352, 14704]"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X_tr_tensor_inf, torch.from_numpy(y_train_pu))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)  # adjust batch_size to your GPU\n",
    "\n",
    "preds_train = []\n",
    "model_mamba.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_X, _ in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model_mamba(batch_X)\n",
    "        preds = torch.where(\n",
    "                    outputs > 0,\n",
    "                    torch.tensor(1, device=outputs.device),\n",
    "                    torch.tensor(-1, device=outputs.device)\n",
    "                ).view(-1) \n",
    "        preds_train.append(preds.cpu())\n",
    "\n",
    "# Concatenate all predictions\n",
    "preds_train = torch.cat(preds_train).numpy()\n",
    "\n",
    "print(classification_report(y_train_pu, preds_train, digits=4))\n",
    "print(confusion_matrix(y_train_pu, preds_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "270c2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.9293    0.9996    0.9632      2737\n",
      "           1     0.6667    0.0095    0.0188       210\n",
      "\n",
      "    accuracy                         0.9291      2947\n",
      "   macro avg     0.7980    0.5046    0.4910      2947\n",
      "weighted avg     0.9106    0.9291    0.8959      2947\n",
      "\n",
      "[[2736    1]\n",
      " [ 208    2]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TensorDataset(X_test_tensor, torch.from_numpy(y_test_pu))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)  # adjust batch_size to your GPU\n",
    "\n",
    "preds_test = []\n",
    "model_mamba.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_X, _ in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model_mamba(batch_X)\n",
    "        preds = torch.where(\n",
    "                    outputs > 0,\n",
    "                    torch.tensor(1, device=outputs.device),\n",
    "                    torch.tensor(-1, device=outputs.device)\n",
    "                ).view(-1) \n",
    "        preds_test.append(preds.cpu())\n",
    "\n",
    "# Concatenate all predictions\n",
    "preds_test = torch.cat(preds_test).numpy()\n",
    "\n",
    "print(classification_report(y_test_pu, preds_test, digits=4))\n",
    "print(confusion_matrix(y_test_pu, preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "611a8aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.8584    1.0000    0.9238      2527\n",
      "           1     1.0000    0.0071    0.0142       420\n",
      "\n",
      "    accuracy                         0.8585      2947\n",
      "   macro avg     0.9292    0.5036    0.4690      2947\n",
      "weighted avg     0.8785    0.8585    0.7941      2947\n",
      "\n",
      "[[2527    0]\n",
      " [ 417    3]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pu = np.where(y_test_np == positive_class, 1, -1)\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.from_numpy(y_test_pu))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)  # adjust batch_size to your GPU\n",
    "\n",
    "preds_test = []\n",
    "model_mamba.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_X, _ in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model_mamba(batch_X)\n",
    "        preds = torch.where(\n",
    "                    outputs > 0,\n",
    "                    torch.tensor(1, device=outputs.device),\n",
    "                    torch.tensor(-1, device=outputs.device)\n",
    "                ).view(-1) \n",
    "        preds_test.append(preds.cpu())\n",
    "\n",
    "# Concatenate all predictions\n",
    "preds_test = torch.cat(preds_test).numpy()\n",
    "\n",
    "print(classification_report(y_test_pu, preds_test, digits=4))\n",
    "print(confusion_matrix(y_test_pu, preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4b799d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Total number of positive sampels:986\n",
      "Total number of unmarked positive sampels: 493\n",
      "Number of unmarked samples correctly predicted as positive: 36\n",
      "In percentage: 0.0730\n",
      "Test\n",
      "Total number of positive sampels:420\n",
      "Total number of unmarked positive sampels: 210\n",
      "Number of unmarked samples correctly predicted as positive: 1\n",
      "In percentage: 0.0048\n"
     ]
    }
   ],
   "source": [
    "# Observe the unmarked positive samples and determine in how many places the prediction matches true labels.\n",
    "print(\"Train\")\n",
    "correct_preds_num_tr = (preds_train[unmark_pos_tr] == y_train[unmark_pos_tr]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_train==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tr)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tr}\\n\\\n",
    "In percentage: {(correct_preds_num_tr/len(unmark_pos_tr)):.4f}\")\n",
    "print(\"Test\")\n",
    "correct_preds_num_tst = (preds_test[unmark_pos_tst] == y_test[unmark_pos_tst]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_test==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tst)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tst}\\n\\\n",
    "In percentage: {(correct_preds_num_tst/len(unmark_pos_tst)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cad0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_mamba.state_dict, \"models/pu_mambe_test1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "156cdd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_mamba.state_dict, \"models/har_mamba_crossentropy.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029b015",
   "metadata": {},
   "source": [
    "## InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "774c6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "from pu_loss import PULoss, PULossWrapped\n",
    "\n",
    "#criterion = PULossWrapped(prior=positive_prior, nnPU=True)\n",
    "criterion = nn.CrossEntropyLoss(weight=ce_weight)\n",
    "\n",
    "X_all = np.concatenate([X_train_np, X_test_np]).astype(np.float32)\n",
    "y_all = np.concatenate([y_train_pu, y_test_pu])\n",
    "\n",
    "splits = (list(range(len(y_train_np))),\n",
    "          list(range(len(y_train_np), len(y_all))))\n",
    "\n",
    "tfms = [None, TSClassification()]\n",
    "batch_tfms = TSStandardize(by_sample=True)\n",
    "\n",
    "clf = TSClassifier(X_all, y_all, splits=splits, arch=\"InceptionTimePlus\",\n",
    "                   tfms=tfms, batch_tfms=batch_tfms,train_metrics=True, loss_func=criterion,\n",
    "                   metrics=accuracy, cbs=ShowGraph(), wd=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1682589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.525599</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.410711</td>\n",
       "      <td>0.748897</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.322969</td>\n",
       "      <td>0.825932</td>\n",
       "      <td>0.487920</td>\n",
       "      <td>0.620631</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246048</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.555033</td>\n",
       "      <td>0.622328</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211627</td>\n",
       "      <td>0.919956</td>\n",
       "      <td>1.268370</td>\n",
       "      <td>0.077706</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181059</td>\n",
       "      <td>0.926672</td>\n",
       "      <td>0.293002</td>\n",
       "      <td>0.835087</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168204</td>\n",
       "      <td>0.930236</td>\n",
       "      <td>1.371067</td>\n",
       "      <td>0.929080</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148223</td>\n",
       "      <td>0.933799</td>\n",
       "      <td>0.491628</td>\n",
       "      <td>0.929080</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.140496</td>\n",
       "      <td>0.935307</td>\n",
       "      <td>0.232708</td>\n",
       "      <td>0.931795</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.132583</td>\n",
       "      <td>0.936541</td>\n",
       "      <td>0.277738</td>\n",
       "      <td>0.929759</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.128533</td>\n",
       "      <td>0.934759</td>\n",
       "      <td>0.242222</td>\n",
       "      <td>0.931116</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf.fit_one_cycle(10, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d9551894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 1, 561)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = X_all.reshape(X_all.shape[0], 1, X_all.shape[1])\n",
    "X_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "da7c3dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9305    0.9640      6859\n",
      "           1     0.5082    1.0000    0.6740       493\n",
      "\n",
      "    accuracy                         0.9351      7352\n",
      "   macro avg     0.7541    0.9652    0.8190      7352\n",
      "weighted avg     0.9670    0.9351    0.9445      7352\n",
      "\n",
      "[[6382  477]\n",
      " [   0  493]]\n"
     ]
    }
   ],
   "source": [
    "# Train metrics\n",
    "\n",
    "probas, target = clf.get_X_preds(X_all[splits[0]], y_all[splits[0]], with_decoded=False)\n",
    "preds_train = probas.argmax(dim=-1)\n",
    "print(classification_report(target, preds_train, digits=4))\n",
    "print(confusion_matrix(target, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "201fe5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9972    0.9997    0.9984      6366\n",
      "           1     0.9979    0.9817    0.9898       986\n",
      "\n",
      "    accuracy                         0.9973      7352\n",
      "   macro avg     0.9976    0.9907    0.9941      7352\n",
      "weighted avg     0.9973    0.9973    0.9973      7352\n",
      "\n",
      "[[6364    2]\n",
      " [  18  968]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, preds_train, digits=4))\n",
    "print(confusion_matrix(y_train, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6418a670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9877    0.9375    0.9619      2737\n",
      "           1     0.5100    0.8476    0.6369       210\n",
      "\n",
      "    accuracy                         0.9311      2947\n",
      "   macro avg     0.7489    0.8926    0.7994      2947\n",
      "weighted avg     0.9536    0.9311    0.9388      2947\n",
      "\n",
      "[[2566  171]\n",
      " [  32  178]]\n"
     ]
    }
   ],
   "source": [
    "# Test metrics\n",
    "\n",
    "probas, target = clf.get_X_preds(X_all[splits[1]], y_all[splits[1]], with_decoded=False)\n",
    "preds_test = probas.argmax(dim=-1)\n",
    "print(classification_report(target, preds, digits=4))\n",
    "print(confusion_matrix(target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d8636796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9727    1.0000    0.9861      2527\n",
      "           1     1.0000    0.8310    0.9077       420\n",
      "\n",
      "    accuracy                         0.9759      2947\n",
      "   macro avg     0.9863    0.9155    0.9469      2947\n",
      "weighted avg     0.9766    0.9759    0.9750      2947\n",
      "\n",
      "[[2527    0]\n",
      " [  71  349]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds, digits=4))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4f30148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Total number of positive sampels:986\n",
      "Total number of unmarked positive sampels: 493\n",
      "Number of unmarked samples correctly predicted as positive: 475\n",
      "In percentage: 0.9635\n",
      "Test\n",
      "Total number of positive sampels:420\n",
      "Total number of unmarked positive sampels: 210\n",
      "Number of unmarked samples correctly predicted as positive: 171\n",
      "In percentage: 0.8143\n"
     ]
    }
   ],
   "source": [
    "# Observe the unmarked positive samples and determine in how many places the prediction matches true labels.\n",
    "print(\"Train\")\n",
    "correct_preds_num_tr = (preds_train[unmark_pos_tr] == y_train[unmark_pos_tr]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_train==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tr)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tr}\\n\\\n",
    "In percentage: {(correct_preds_num_tr/len(unmark_pos_tr)):.4f}\")\n",
    "print(\"Test\")\n",
    "correct_preds_num_tst = (preds_test[unmark_pos_tst] == y_test[unmark_pos_tst]).sum()\n",
    "print(f\"Total number of positive sampels:{(y_test==1).sum()}\\n\\\n",
    "Total number of unmarked positive sampels: {len(unmark_pos_tst)}\\n\\\n",
    "Number of unmarked samples correctly predicted as positive: {correct_preds_num_tst}\\n\\\n",
    "In percentage: {(correct_preds_num_tst/len(unmark_pos_tst)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa43237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[319], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate-spaces/mamba-130m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m )\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:315\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:5001\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4992\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4994\u001b[0m     (\n\u001b[1;32m   4995\u001b[0m         model,\n\u001b[1;32m   4996\u001b[0m         missing_keys,\n\u001b[1;32m   4997\u001b[0m         unexpected_keys,\n\u001b[1;32m   4998\u001b[0m         mismatched_keys,\n\u001b[1;32m   4999\u001b[0m         offload_index,\n\u001b[1;32m   5000\u001b[0m         error_msgs,\n\u001b[0;32m-> 5001\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5007\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5010\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5017\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5018\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   5019\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:5262\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5259\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(state_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   5260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5261\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m-> 5262\u001b[0m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m   5263\u001b[0m     )\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[1;32m   5266\u001b[0m prefix \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbase_model_prefix\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:560\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# Fallback to torch.load (if weights_only was explicitly False, do not check safety as this is known to be unsafe)\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mcheck_torch_load_is_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/aic/har-pu-learning/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1606\u001b[0m, in \u001b[0;36mcheck_torch_load_is_safe\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_torch_load_is_safe\u001b[39m():\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.6\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1606\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1607\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDue to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1608\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen loading files with safetensors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1611\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434"
     ]
    }
   ],
   "source": [
    "from transformers import MambaConfig, MambaModel \n",
    "# config = MambaConfig(\n",
    "#     d_model=128,         # Hidden size appropriate for your HAR data\n",
    "#     n_layer=12,          # Number of sequence layers\n",
    "#     vocab_size=None,     # Not relevant for time series, you can omit or set extraneously\n",
    "#     # Set other config options as needed\n",
    "# )\n",
    "# model = MambaModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1f916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
